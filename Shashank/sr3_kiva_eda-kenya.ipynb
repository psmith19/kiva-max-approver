{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva = pd.read_csv('kivasmall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419156, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables of interest: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51170, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake = kiva[kiva['COUNTRY_CODE']=='KE']\n",
    "kivake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE     1144\n",
       "LOAN_AMOUNT              0\n",
       "STATUS                   0\n",
       "ACTIVITY_NAME            0\n",
       "SECTOR_NAME              0\n",
       "COUNTRY_CODE             0\n",
       "LENDER_TERM              0\n",
       "REPAYMENT_INTERVAL       0\n",
       "DISTRIBUTION_MODEL       0\n",
       "word_count_DT            0\n",
       "word_count_TAGS          0\n",
       "word_count_LU            0\n",
       "char_count_DT            0\n",
       "char_count_TAGS          0\n",
       "char_count_LU            0\n",
       "month                    0\n",
       "FEM_COUNT             1144\n",
       "MALE_COUNT            1144\n",
       "PIC_TRUE_COUNT        1144\n",
       "PIC_FALSE_COUNT       1144\n",
       "ANY_FEM               1144\n",
       "ANY_MALE              1144\n",
       "word_char_DT             0\n",
       "word_char_TAGS           0\n",
       "word_char_LU             0\n",
       "MALE_FEM              1144\n",
       "MALE_PIC              1144\n",
       "FEM_PIC               1144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = {'ORIGINAL_LANGUAGE' : 'MISSING', 'FEM_COUNT' : 0, 'MALE_COUNT' : 0,'PIC_TRUE_COUNT' : 0, 'PIC_FALSE_COUNT' : 0,'ANY_FEM' : 0,'ANY_MALE' : 0,'COUNTRY_CODE':'MISSING', 'MALE_FEM':0,'MALE_PIC':0,'FEM_PIC':0}\n",
    "kivake.fillna(value = fill_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE     0\n",
       "LOAN_AMOUNT           0\n",
       "STATUS                0\n",
       "ACTIVITY_NAME         0\n",
       "SECTOR_NAME           0\n",
       "COUNTRY_CODE          0\n",
       "LENDER_TERM           0\n",
       "REPAYMENT_INTERVAL    0\n",
       "DISTRIBUTION_MODEL    0\n",
       "word_count_DT         0\n",
       "word_count_TAGS       0\n",
       "word_count_LU         0\n",
       "char_count_DT         0\n",
       "char_count_TAGS       0\n",
       "char_count_LU         0\n",
       "month                 0\n",
       "FEM_COUNT             0\n",
       "MALE_COUNT            0\n",
       "PIC_TRUE_COUNT        0\n",
       "PIC_FALSE_COUNT       0\n",
       "ANY_FEM               0\n",
       "ANY_MALE              0\n",
       "word_char_DT          0\n",
       "word_char_TAGS        0\n",
       "word_char_LU          0\n",
       "MALE_FEM              0\n",
       "MALE_PIC              0\n",
       "FEM_PIC               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORIGINAL_LANGUAGE', 'LOAN_AMOUNT', 'STATUS', 'ACTIVITY_NAME',\n",
       "       'SECTOR_NAME', 'COUNTRY_CODE', 'LENDER_TERM', 'REPAYMENT_INTERVAL',\n",
       "       'DISTRIBUTION_MODEL', 'word_count_DT', 'word_count_TAGS',\n",
       "       'word_count_LU', 'char_count_DT', 'char_count_TAGS', 'char_count_LU',\n",
       "       'month', 'FEM_COUNT', 'MALE_COUNT', 'PIC_TRUE_COUNT', 'PIC_FALSE_COUNT',\n",
       "       'ANY_FEM', 'ANY_MALE', 'word_char_DT', 'word_char_TAGS', 'word_char_LU',\n",
       "       'MALE_FEM', 'MALE_PIC', 'FEM_PIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE      object\n",
       "LOAN_AMOUNT           float64\n",
       "STATUS                  int64\n",
       "ACTIVITY_NAME          object\n",
       "SECTOR_NAME            object\n",
       "COUNTRY_CODE           object\n",
       "LENDER_TERM           float64\n",
       "REPAYMENT_INTERVAL     object\n",
       "DISTRIBUTION_MODEL     object\n",
       "word_count_DT           int64\n",
       "word_count_TAGS         int64\n",
       "word_count_LU           int64\n",
       "char_count_DT           int64\n",
       "char_count_TAGS         int64\n",
       "char_count_LU           int64\n",
       "month                   int64\n",
       "FEM_COUNT             float64\n",
       "MALE_COUNT            float64\n",
       "PIC_TRUE_COUNT        float64\n",
       "PIC_FALSE_COUNT       float64\n",
       "ANY_FEM               float64\n",
       "ANY_MALE              float64\n",
       "word_char_DT            int64\n",
       "word_char_TAGS          int64\n",
       "word_char_LU            int64\n",
       "MALE_FEM              float64\n",
       "MALE_PIC              float64\n",
       "FEM_PIC               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51170, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                count      mean\n",
      "ACTIVITY_NAME                                  \n",
      "Agriculture                      2283  0.833552\n",
      "Animal Sales                      179  0.743017\n",
      "Bakery                             52  0.653846\n",
      "Beauty Salon                      700  0.652857\n",
      "Beverages                          68  0.735294\n",
      "Cattle                            113  0.769912\n",
      "Cereals                          2689  0.732614\n",
      "Charcoal Sales                    343  0.760933\n",
      "Clothing                          342  0.903509\n",
      "Clothing Sales                   1457  0.636925\n",
      "Cosmetics Sales                   208  0.634615\n",
      "Crafts                             45  0.977778\n",
      "Dairy                            2669  0.826527\n",
      "Education provider                 69  1.000000\n",
      "Farm Supplies                     230  0.756522\n",
      "Farming                         19741  0.822197\n",
      "Fish Selling                      407  0.778870\n",
      "Fishing                             6  0.833333\n",
      "Food                              552  0.798913\n",
      "Food Market                       183  0.830601\n",
      "Food Production/Sales             352  0.823864\n",
      "Food Stall                        434  0.829493\n",
      "Fruits & Vegetables              1532  0.845953\n",
      "General Store                    2511  0.586619\n",
      "Grocery Store                     891  0.809203\n",
      "Higher education costs            191  0.926702\n",
      "Home Appliances                   199  1.000000\n",
      "Home Energy                      1786  1.000000\n",
      "Home Products Sales               171  0.619883\n",
      "Livestock                         314  0.856688\n",
      "Motorcycle Transport             1417  0.474947\n",
      "Personal Expenses                  33  0.939394\n",
      "Personal Housing Expenses          49  0.959184\n",
      "Personal Medical Expenses          32  1.000000\n",
      "Personal Products Sales            19  0.684211\n",
      "Pigs                               50  0.800000\n",
      "Poultry                          1164  0.909794\n",
      "Primary/secondary school costs    668  1.000000\n",
      "Restaurant                        260  0.626923\n",
      "Retail                           1628  0.653563\n",
      "Services                          466  0.742489\n",
      "Sewing                             23  0.869565\n",
      "Tailoring                         679  0.837997\n",
      "Transportation                    146  0.595890\n",
      "Used Clothing                     389  0.789203\n",
      "Weaving                            44  1.000000\n",
      "miscellaneous                    3386  0.711164\n",
      "                count      mean\n",
      "SECTOR_NAME                    \n",
      "Agriculture     26810  0.826632\n",
      "Arts              121  0.983471\n",
      "Clothing         2232  0.707437\n",
      "Construction      372  0.854839\n",
      "Education         929  0.984930\n",
      "Entertainment      17  1.000000\n",
      "Food             7956  0.772247\n",
      "Health            167  1.000000\n",
      "Housing           201  0.656716\n",
      "Manufacturing     189  0.989418\n",
      "Personal Use     2033  0.997541\n",
      "Retail           5849  0.618396\n",
      "Services         2616  0.740443\n",
      "Transportation   1662  0.489771\n",
      "Wholesale          16  0.937500\n",
      "              count      mean\n",
      "COUNTRY_CODE                 \n",
      "KE            51170  0.784659\n",
      "                    count      mean\n",
      "REPAYMENT_INTERVAL                 \n",
      "bullet               7903  0.839048\n",
      "irregular             400  0.930000\n",
      "monthly             42867  0.773275\n",
      "                    count      mean\n",
      "DISTRIBUTION_MODEL                 \n",
      "direct                907  1.000000\n",
      "field_partner       50263  0.780773\n",
      "       count      mean\n",
      "month                 \n",
      "0       4379  0.755195\n",
      "1       9213  0.789645\n",
      "2       7693  0.878591\n",
      "3       4907  0.835949\n",
      "4       4682  0.715933\n",
      "5       4623  0.724854\n",
      "6       4180  0.738038\n",
      "7       4062  0.726243\n",
      "8       3610  0.778116\n",
      "9       3821  0.827270\n"
     ]
    }
   ],
   "source": [
    "catcols = ['ORIGINAL_LANGUAGE', 'ACTIVITY_NAME', 'SECTOR_NAME', 'COUNTRY_CODE', 'REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'month']\n",
    "\n",
    "for i in range(1,len(catcols)):\n",
    "    print(kivake.groupby(catcols[i], dropna=False)['STATUS'].agg(['count', 'mean']))\n",
    "    #print(pd.pivot_table(df, columns = totcols[i], aggfunc=np.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "kivake_dummies = pd.get_dummies(kivake, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51170, 88)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kivake_dummies_small = kivake_dummies.sample(51170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40151\n",
       "0    11019\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake_dummies_small['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X, y and test-train split\n",
    "X = kivake_dummies_small.drop(columns = ['STATUS'])\n",
    "y = kivake_dummies_small['STATUS']\n",
    "\n",
    "#Perform test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42, stratify=y)\n",
    "\n",
    "#Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8312270370273862 0.8270147737043696\n"
     ]
    }
   ],
   "source": [
    "#Building out logistic regressoin with higher max-iter\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1200)\n",
    "logreg.fit(X_train_sc, y_train)\n",
    "print(logreg.score(X_train_sc,y_train), logreg.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.400045</td>\n",
       "      <td>word_char_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.256775</td>\n",
       "      <td>LOAN_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.161398</td>\n",
       "      <td>ORIGINAL_LANGUAGE_MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.161398</td>\n",
       "      <td>ANY_MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.945255</td>\n",
       "      <td>word_count_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.319407</td>\n",
       "      <td>FEM_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.110805</td>\n",
       "      <td>ACTIVITY_NAME_Home Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.745742</td>\n",
       "      <td>word_count_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.701043</td>\n",
       "      <td>MALE_PIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.675147</td>\n",
       "      <td>PIC_TRUE_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.674324</td>\n",
       "      <td>MALE_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>-0.629373</td>\n",
       "      <td>DISTRIBUTION_MODEL_field_partner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.530693</td>\n",
       "      <td>char_count_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>-0.528588</td>\n",
       "      <td>SECTOR_NAME_Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.519693</td>\n",
       "      <td>SECTOR_NAME_Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.480569</td>\n",
       "      <td>SECTOR_NAME_Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.472950</td>\n",
       "      <td>SECTOR_NAME_Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.456972</td>\n",
       "      <td>char_count_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>-0.439381</td>\n",
       "      <td>REPAYMENT_INTERVAL_monthly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.379478</td>\n",
       "      <td>FEM_PIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.379350</td>\n",
       "      <td>MALE_FEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>-0.351749</td>\n",
       "      <td>SECTOR_NAME_Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.344896</td>\n",
       "      <td>ACTIVITY_NAME_Primary/secondary school costs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.343141</td>\n",
       "      <td>ANY_FEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.334363</td>\n",
       "      <td>ACTIVITY_NAME_Home Appliances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coefficients                                      features\n",
       "16      3.400045                                word_char_TAGS\n",
       "0      -2.256775                                   LOAN_AMOUNT\n",
       "21      2.161398                     ORIGINAL_LANGUAGE_MISSING\n",
       "14     -2.161398                                      ANY_MALE\n",
       "3      -1.945255                               word_count_TAGS\n",
       "9       1.319407                                     FEM_COUNT\n",
       "50      1.110805                     ACTIVITY_NAME_Home Energy\n",
       "2      -0.745742                                 word_count_DT\n",
       "19      0.701043                                      MALE_PIC\n",
       "11     -0.675147                                PIC_TRUE_COUNT\n",
       "10     -0.674324                                    MALE_COUNT\n",
       "86     -0.629373              DISTRIBUTION_MODEL_field_partner\n",
       "5       0.530693                                 char_count_DT\n",
       "75     -0.528588                              SECTOR_NAME_Food\n",
       "80     -0.519693                            SECTOR_NAME_Retail\n",
       "76      0.480569                            SECTOR_NAME_Health\n",
       "73      0.472950                         SECTOR_NAME_Education\n",
       "7      -0.456972                                 char_count_LU\n",
       "85     -0.439381                    REPAYMENT_INTERVAL_monthly\n",
       "20     -0.379478                                       FEM_PIC\n",
       "18     -0.379350                                      MALE_FEM\n",
       "71     -0.351749                          SECTOR_NAME_Clothing\n",
       "60      0.344896  ACTIVITY_NAME_Primary/secondary school costs\n",
       "13      0.343141                                       ANY_FEM\n",
       "49      0.334363                 ACTIVITY_NAME_Home Appliances"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See what coefficients came out strong\n",
    "coef= logreg.coef_[0]\n",
    "coef_df = pd.DataFrame({'coefficients': coef, 'features': X_train.columns}).sort_values(by = 'coefficients', ascending = False, key = abs).head(25)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get predictions \n",
    "preds = logreg.predict(X_test_sc)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "ConfusionMatrixDisplay(cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Various scores:  AUROC: 0.6738178045025998, ACC_SCORE: 0.8270147737043696, REC_SCORE: 0.942916915720263, PREC_SCORE: 0.8523187753264295,F1: 0.8953317882987277\n"
     ]
    }
   ],
   "source": [
    "print(f'Various scores:  AUROC: {roc_auc_score(y_test, preds)}, ACC_SCORE: {accuracy_score(y_test, preds)}, REC_SCORE: {recall_score(y_test, preds)}, PREC_SCORE: {precision_score(y_test, preds)},F1: {f1_score(y_test, preds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of the model classes to test\n",
    "model_list = [\n",
    "    #LogisticRegression(),\n",
    "    #DecisionTreeClassifier(),\n",
    "    #BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    #ExtraTreesClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list to store each model's results in a dictionary\n",
    "classifier_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train_sc, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train_sc, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test_sc, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train_sc, y_train, cv = 5).mean()\n",
    "        \n",
    "    #add the dictionary to the list\n",
    "    classifier_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846948</td>\n",
       "      <td>0.847747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.842770</td>\n",
       "      <td>0.839834</td>\n",
       "      <td>0.843839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.850483</td>\n",
       "      <td>0.844446</td>\n",
       "      <td>0.847852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  train_score  test_score  cv_score\n",
       "0      RandomForestClassifier()     1.000000    0.846948  0.847747\n",
       "1          AdaBoostClassifier()     0.842770    0.839834  0.843839\n",
       "2  GradientBoostingClassifier()     0.850483    0.844446  0.847852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get just RF model scores\n",
    "clf_results = pd.DataFrame(classifier_list)\n",
    "clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 - 1s - loss: 1.2249 - acc: 0.3503 - val_loss: 0.7241 - val_acc: 0.5638\n",
      "Epoch 2/100\n",
      "5/5 - 0s - loss: 0.8746 - acc: 0.5019 - val_loss: 0.5644 - val_acc: 0.7714\n",
      "Epoch 3/100\n",
      "5/5 - 0s - loss: 0.6937 - acc: 0.6420 - val_loss: 0.5274 - val_acc: 0.7847\n",
      "Epoch 4/100\n",
      "5/5 - 0s - loss: 0.6218 - acc: 0.7211 - val_loss: 0.5288 - val_acc: 0.7846\n",
      "Epoch 5/100\n",
      "5/5 - 0s - loss: 0.5997 - acc: 0.7527 - val_loss: 0.5307 - val_acc: 0.7846\n",
      "Epoch 6/100\n",
      "5/5 - 0s - loss: 0.5918 - acc: 0.7628 - val_loss: 0.5231 - val_acc: 0.7846\n",
      "Epoch 7/100\n",
      "5/5 - 0s - loss: 0.5778 - acc: 0.7679 - val_loss: 0.5086 - val_acc: 0.7846\n",
      "Epoch 8/100\n",
      "5/5 - 0s - loss: 0.5597 - acc: 0.7713 - val_loss: 0.4924 - val_acc: 0.7846\n",
      "Epoch 9/100\n",
      "5/5 - 0s - loss: 0.5472 - acc: 0.7723 - val_loss: 0.4787 - val_acc: 0.7864\n",
      "Epoch 10/100\n",
      "5/5 - 0s - loss: 0.5336 - acc: 0.7700 - val_loss: 0.4680 - val_acc: 0.7916\n",
      "Epoch 11/100\n",
      "5/5 - 0s - loss: 0.5183 - acc: 0.7723 - val_loss: 0.4598 - val_acc: 0.7937\n",
      "Epoch 12/100\n",
      "5/5 - 0s - loss: 0.5122 - acc: 0.7730 - val_loss: 0.4534 - val_acc: 0.7944\n",
      "Epoch 13/100\n",
      "5/5 - 0s - loss: 0.5058 - acc: 0.7729 - val_loss: 0.4480 - val_acc: 0.7952\n",
      "Epoch 14/100\n",
      "5/5 - 0s - loss: 0.4959 - acc: 0.7775 - val_loss: 0.4432 - val_acc: 0.7958\n",
      "Epoch 15/100\n",
      "5/5 - 0s - loss: 0.4904 - acc: 0.7796 - val_loss: 0.4387 - val_acc: 0.7960\n",
      "Epoch 16/100\n",
      "5/5 - 0s - loss: 0.4836 - acc: 0.7808 - val_loss: 0.4347 - val_acc: 0.7965\n",
      "Epoch 17/100\n",
      "5/5 - 0s - loss: 0.4786 - acc: 0.7857 - val_loss: 0.4308 - val_acc: 0.7968\n",
      "Epoch 18/100\n",
      "5/5 - 0s - loss: 0.4740 - acc: 0.7853 - val_loss: 0.4272 - val_acc: 0.7965\n",
      "Epoch 19/100\n",
      "5/5 - 0s - loss: 0.4721 - acc: 0.7846 - val_loss: 0.4235 - val_acc: 0.7968\n",
      "Epoch 20/100\n",
      "5/5 - 0s - loss: 0.4632 - acc: 0.7899 - val_loss: 0.4200 - val_acc: 0.7977\n",
      "Epoch 21/100\n",
      "5/5 - 0s - loss: 0.4616 - acc: 0.7896 - val_loss: 0.4167 - val_acc: 0.7985\n",
      "Epoch 22/100\n",
      "5/5 - 0s - loss: 0.4562 - acc: 0.7897 - val_loss: 0.4138 - val_acc: 0.7995\n",
      "Epoch 23/100\n",
      "5/5 - 0s - loss: 0.4539 - acc: 0.7884 - val_loss: 0.4112 - val_acc: 0.8007\n",
      "Epoch 24/100\n",
      "5/5 - 0s - loss: 0.4496 - acc: 0.7938 - val_loss: 0.4086 - val_acc: 0.8025\n",
      "Epoch 25/100\n",
      "5/5 - 0s - loss: 0.4443 - acc: 0.7933 - val_loss: 0.4063 - val_acc: 0.8036\n",
      "Epoch 26/100\n",
      "5/5 - 0s - loss: 0.4412 - acc: 0.7954 - val_loss: 0.4040 - val_acc: 0.8040\n",
      "Epoch 27/100\n",
      "5/5 - 0s - loss: 0.4403 - acc: 0.7943 - val_loss: 0.4017 - val_acc: 0.8050\n",
      "Epoch 28/100\n",
      "5/5 - 0s - loss: 0.4384 - acc: 0.7964 - val_loss: 0.3997 - val_acc: 0.8056\n",
      "Epoch 29/100\n",
      "5/5 - 0s - loss: 0.4354 - acc: 0.7983 - val_loss: 0.3979 - val_acc: 0.8058\n",
      "Epoch 30/100\n",
      "5/5 - 0s - loss: 0.4303 - acc: 0.8005 - val_loss: 0.3961 - val_acc: 0.8071\n",
      "Epoch 31/100\n",
      "5/5 - 0s - loss: 0.4255 - acc: 0.7995 - val_loss: 0.3945 - val_acc: 0.8080\n",
      "Epoch 32/100\n",
      "5/5 - 0s - loss: 0.4286 - acc: 0.8000 - val_loss: 0.3930 - val_acc: 0.8083\n",
      "Epoch 33/100\n",
      "5/5 - 0s - loss: 0.4262 - acc: 0.7990 - val_loss: 0.3915 - val_acc: 0.8090\n",
      "Epoch 34/100\n",
      "5/5 - 0s - loss: 0.4216 - acc: 0.8038 - val_loss: 0.3900 - val_acc: 0.8102\n",
      "Epoch 35/100\n",
      "5/5 - 0s - loss: 0.4198 - acc: 0.8021 - val_loss: 0.3887 - val_acc: 0.8114\n",
      "Epoch 36/100\n",
      "5/5 - 0s - loss: 0.4181 - acc: 0.8030 - val_loss: 0.3872 - val_acc: 0.8125\n",
      "Epoch 37/100\n",
      "5/5 - 0s - loss: 0.4150 - acc: 0.8056 - val_loss: 0.3858 - val_acc: 0.8137\n",
      "Epoch 38/100\n",
      "5/5 - 0s - loss: 0.4178 - acc: 0.8035 - val_loss: 0.3845 - val_acc: 0.8147\n",
      "Epoch 39/100\n",
      "5/5 - 0s - loss: 0.4116 - acc: 0.8077 - val_loss: 0.3833 - val_acc: 0.8154\n",
      "Epoch 40/100\n",
      "5/5 - 0s - loss: 0.4083 - acc: 0.8086 - val_loss: 0.3821 - val_acc: 0.8167\n",
      "Epoch 41/100\n",
      "5/5 - 0s - loss: 0.4091 - acc: 0.8096 - val_loss: 0.3812 - val_acc: 0.8169\n",
      "Epoch 42/100\n",
      "5/5 - 0s - loss: 0.4092 - acc: 0.8080 - val_loss: 0.3803 - val_acc: 0.8180\n",
      "Epoch 43/100\n",
      "5/5 - 0s - loss: 0.4075 - acc: 0.8075 - val_loss: 0.3793 - val_acc: 0.8179\n",
      "Epoch 44/100\n",
      "5/5 - 0s - loss: 0.4055 - acc: 0.8095 - val_loss: 0.3786 - val_acc: 0.8179\n",
      "Epoch 45/100\n",
      "5/5 - 0s - loss: 0.4021 - acc: 0.8125 - val_loss: 0.3774 - val_acc: 0.8193\n",
      "Epoch 46/100\n",
      "5/5 - 0s - loss: 0.4003 - acc: 0.8144 - val_loss: 0.3764 - val_acc: 0.8196\n",
      "Epoch 47/100\n",
      "5/5 - 0s - loss: 0.3988 - acc: 0.8115 - val_loss: 0.3754 - val_acc: 0.8201\n",
      "Epoch 48/100\n",
      "5/5 - 0s - loss: 0.3985 - acc: 0.8114 - val_loss: 0.3745 - val_acc: 0.8205\n",
      "Epoch 49/100\n",
      "5/5 - 0s - loss: 0.3977 - acc: 0.8130 - val_loss: 0.3734 - val_acc: 0.8215\n",
      "Epoch 50/100\n",
      "5/5 - 0s - loss: 0.3967 - acc: 0.8125 - val_loss: 0.3725 - val_acc: 0.8221\n",
      "Epoch 51/100\n",
      "5/5 - 0s - loss: 0.3936 - acc: 0.8151 - val_loss: 0.3717 - val_acc: 0.8224\n",
      "Epoch 52/100\n",
      "5/5 - 0s - loss: 0.3913 - acc: 0.8159 - val_loss: 0.3708 - val_acc: 0.8229\n",
      "Epoch 53/100\n",
      "5/5 - 0s - loss: 0.3914 - acc: 0.8158 - val_loss: 0.3698 - val_acc: 0.8222\n",
      "Epoch 54/100\n",
      "5/5 - 0s - loss: 0.3927 - acc: 0.8156 - val_loss: 0.3689 - val_acc: 0.8230\n",
      "Epoch 55/100\n",
      "5/5 - 0s - loss: 0.3901 - acc: 0.8167 - val_loss: 0.3680 - val_acc: 0.8233\n",
      "Epoch 56/100\n",
      "5/5 - 0s - loss: 0.3875 - acc: 0.8194 - val_loss: 0.3675 - val_acc: 0.8238\n",
      "Epoch 57/100\n",
      "5/5 - 0s - loss: 0.3875 - acc: 0.8193 - val_loss: 0.3668 - val_acc: 0.8238\n",
      "Epoch 58/100\n",
      "5/5 - 0s - loss: 0.3875 - acc: 0.8187 - val_loss: 0.3661 - val_acc: 0.8240\n",
      "Epoch 59/100\n",
      "5/5 - 0s - loss: 0.3854 - acc: 0.8195 - val_loss: 0.3654 - val_acc: 0.8243\n",
      "Epoch 60/100\n",
      "5/5 - 0s - loss: 0.3830 - acc: 0.8209 - val_loss: 0.3646 - val_acc: 0.8246\n",
      "Epoch 61/100\n",
      "5/5 - 0s - loss: 0.3841 - acc: 0.8200 - val_loss: 0.3639 - val_acc: 0.8247\n",
      "Epoch 62/100\n",
      "5/5 - 0s - loss: 0.3851 - acc: 0.8187 - val_loss: 0.3636 - val_acc: 0.8251\n",
      "Epoch 63/100\n",
      "5/5 - 0s - loss: 0.3809 - acc: 0.8213 - val_loss: 0.3629 - val_acc: 0.8260\n",
      "Epoch 64/100\n",
      "5/5 - 0s - loss: 0.3802 - acc: 0.8231 - val_loss: 0.3619 - val_acc: 0.8264\n",
      "Epoch 65/100\n",
      "5/5 - 0s - loss: 0.3808 - acc: 0.8223 - val_loss: 0.3612 - val_acc: 0.8263\n",
      "Epoch 66/100\n",
      "5/5 - 0s - loss: 0.3780 - acc: 0.8240 - val_loss: 0.3608 - val_acc: 0.8265\n",
      "Epoch 67/100\n",
      "5/5 - 0s - loss: 0.3782 - acc: 0.8231 - val_loss: 0.3604 - val_acc: 0.8267\n",
      "Epoch 68/100\n",
      "5/5 - 0s - loss: 0.3777 - acc: 0.8228 - val_loss: 0.3596 - val_acc: 0.8279\n",
      "Epoch 69/100\n",
      "5/5 - 0s - loss: 0.3775 - acc: 0.8236 - val_loss: 0.3587 - val_acc: 0.8284\n",
      "Epoch 70/100\n",
      "5/5 - 0s - loss: 0.3744 - acc: 0.8235 - val_loss: 0.3582 - val_acc: 0.8280\n",
      "Epoch 71/100\n",
      "5/5 - 0s - loss: 0.3739 - acc: 0.8255 - val_loss: 0.3576 - val_acc: 0.8283\n",
      "Epoch 72/100\n",
      "5/5 - 0s - loss: 0.3733 - acc: 0.8244 - val_loss: 0.3572 - val_acc: 0.8286\n",
      "Epoch 73/100\n",
      "5/5 - 0s - loss: 0.3744 - acc: 0.8226 - val_loss: 0.3567 - val_acc: 0.8294\n",
      "Epoch 74/100\n",
      "5/5 - 0s - loss: 0.3705 - acc: 0.8269 - val_loss: 0.3562 - val_acc: 0.8298\n",
      "Epoch 75/100\n",
      "5/5 - 0s - loss: 0.3720 - acc: 0.8255 - val_loss: 0.3557 - val_acc: 0.8301\n",
      "Epoch 76/100\n",
      "5/5 - 0s - loss: 0.3728 - acc: 0.8247 - val_loss: 0.3553 - val_acc: 0.8305\n",
      "Epoch 77/100\n",
      "5/5 - 0s - loss: 0.3705 - acc: 0.8274 - val_loss: 0.3551 - val_acc: 0.8309\n",
      "Epoch 78/100\n",
      "5/5 - 0s - loss: 0.3687 - acc: 0.8256 - val_loss: 0.3547 - val_acc: 0.8310\n",
      "Epoch 79/100\n",
      "5/5 - 0s - loss: 0.3690 - acc: 0.8277 - val_loss: 0.3539 - val_acc: 0.8312\n",
      "Epoch 80/100\n",
      "5/5 - 0s - loss: 0.3678 - acc: 0.8264 - val_loss: 0.3530 - val_acc: 0.8315\n",
      "Epoch 81/100\n",
      "5/5 - 0s - loss: 0.3671 - acc: 0.8287 - val_loss: 0.3524 - val_acc: 0.8319\n",
      "Epoch 82/100\n",
      "5/5 - 0s - loss: 0.3663 - acc: 0.8285 - val_loss: 0.3523 - val_acc: 0.8320\n",
      "Epoch 83/100\n",
      "5/5 - 0s - loss: 0.3647 - acc: 0.8290 - val_loss: 0.3524 - val_acc: 0.8321\n",
      "Epoch 84/100\n",
      "5/5 - 0s - loss: 0.3637 - acc: 0.8311 - val_loss: 0.3518 - val_acc: 0.8328\n",
      "Epoch 85/100\n",
      "5/5 - 0s - loss: 0.3642 - acc: 0.8291 - val_loss: 0.3508 - val_acc: 0.8321\n",
      "Epoch 86/100\n",
      "5/5 - 0s - loss: 0.3642 - acc: 0.8285 - val_loss: 0.3500 - val_acc: 0.8334\n",
      "Epoch 87/100\n",
      "5/5 - 0s - loss: 0.3659 - acc: 0.8288 - val_loss: 0.3495 - val_acc: 0.8336\n",
      "Epoch 88/100\n",
      "5/5 - 0s - loss: 0.3625 - acc: 0.8293 - val_loss: 0.3493 - val_acc: 0.8343\n",
      "Epoch 89/100\n",
      "5/5 - 0s - loss: 0.3632 - acc: 0.8300 - val_loss: 0.3491 - val_acc: 0.8337\n",
      "Epoch 90/100\n",
      "5/5 - 0s - loss: 0.3613 - acc: 0.8311 - val_loss: 0.3489 - val_acc: 0.8329\n",
      "Epoch 91/100\n",
      "5/5 - 0s - loss: 0.3618 - acc: 0.8304 - val_loss: 0.3483 - val_acc: 0.8328\n",
      "Epoch 92/100\n",
      "5/5 - 0s - loss: 0.3604 - acc: 0.8330 - val_loss: 0.3476 - val_acc: 0.8350\n",
      "Epoch 93/100\n",
      "5/5 - 0s - loss: 0.3580 - acc: 0.8294 - val_loss: 0.3475 - val_acc: 0.8349\n",
      "Epoch 94/100\n",
      "5/5 - 0s - loss: 0.3600 - acc: 0.8312 - val_loss: 0.3472 - val_acc: 0.8351\n",
      "Epoch 95/100\n",
      "5/5 - 0s - loss: 0.3582 - acc: 0.8323 - val_loss: 0.3465 - val_acc: 0.8356\n",
      "Epoch 96/100\n",
      "5/5 - 0s - loss: 0.3573 - acc: 0.8330 - val_loss: 0.3462 - val_acc: 0.8353\n",
      "Epoch 97/100\n",
      "5/5 - 0s - loss: 0.3588 - acc: 0.8322 - val_loss: 0.3461 - val_acc: 0.8355\n",
      "Epoch 98/100\n",
      "5/5 - 0s - loss: 0.3585 - acc: 0.8316 - val_loss: 0.3462 - val_acc: 0.8351\n",
      "Epoch 99/100\n",
      "5/5 - 0s - loss: 0.3559 - acc: 0.8335 - val_loss: 0.3462 - val_acc: 0.8348\n",
      "Epoch 100/100\n",
      "5/5 - 0s - loss: 0.3561 - acc: 0.8330 - val_loss: 0.3462 - val_acc: 0.8351\n"
     ]
    }
   ],
   "source": [
    "# Build a model using Dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model_dropout = Sequential()\n",
    "\n",
    "#First layer\n",
    "model_dropout.add(Dense(64, activation='relu', input_shape=(X_train_sc.shape[1],)))\n",
    "model_dropout.add(Dropout(0.5))\n",
    "\n",
    "#Second layer\n",
    "model_dropout.add(Dense(64, activation='relu'))\n",
    "model_dropout.add(Dropout(0.5))\n",
    "\n",
    "#Output layer\n",
    "model_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#COmpile the model\n",
    "model_dropout.compile(loss='bce', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "results_dropout = model_dropout.fit(X_train_sc, y_train,\n",
    "                                   validation_data=(X_test_sc, y_test),\n",
    "                                   batch_size=9192,\n",
    "                                   epochs=100,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 0s - loss: 0.3552 - acc: 0.8307 - val_loss: 0.3448 - val_acc: 0.8364\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.3546 - acc: 0.8345 - val_loss: 0.3445 - val_acc: 0.8363\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.3535 - acc: 0.8343 - val_loss: 0.3437 - val_acc: 0.8353\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.3531 - acc: 0.8335 - val_loss: 0.3433 - val_acc: 0.8351\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.3513 - acc: 0.8356 - val_loss: 0.3430 - val_acc: 0.8355\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.3524 - acc: 0.8363 - val_loss: 0.3424 - val_acc: 0.8363\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.3513 - acc: 0.8339 - val_loss: 0.3417 - val_acc: 0.8373\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.3496 - acc: 0.8353 - val_loss: 0.3416 - val_acc: 0.8375\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 0.3498 - acc: 0.8347 - val_loss: 0.3417 - val_acc: 0.8366\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 0.3508 - acc: 0.8350 - val_loss: 0.3412 - val_acc: 0.8367\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 0.3454 - acc: 0.8371 - val_loss: 0.3399 - val_acc: 0.8377\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 0.3469 - acc: 0.8364 - val_loss: 0.3401 - val_acc: 0.8371\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 0.3478 - acc: 0.8378 - val_loss: 0.3401 - val_acc: 0.8378\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 0.3468 - acc: 0.8381 - val_loss: 0.3399 - val_acc: 0.8380\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 0.3459 - acc: 0.8379 - val_loss: 0.3393 - val_acc: 0.8390\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 0.3468 - acc: 0.8366 - val_loss: 0.3397 - val_acc: 0.8393\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 0.3454 - acc: 0.8369 - val_loss: 0.3393 - val_acc: 0.8394\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 0.3441 - acc: 0.8388 - val_loss: 0.3391 - val_acc: 0.8398\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 0.3450 - acc: 0.8366 - val_loss: 0.3385 - val_acc: 0.8402\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 0.3436 - acc: 0.8379 - val_loss: 0.3389 - val_acc: 0.8391\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 0.3437 - acc: 0.8392 - val_loss: 0.3383 - val_acc: 0.8398\n",
      "Epoch 22/100\n",
      "8/8 - 0s - loss: 0.3420 - acc: 0.8384 - val_loss: 0.3384 - val_acc: 0.8391\n",
      "Epoch 23/100\n",
      "8/8 - 0s - loss: 0.3434 - acc: 0.8383 - val_loss: 0.3377 - val_acc: 0.8401\n",
      "Epoch 24/100\n",
      "8/8 - 0s - loss: 0.3432 - acc: 0.8377 - val_loss: 0.3381 - val_acc: 0.8402\n",
      "Epoch 25/100\n",
      "8/8 - 0s - loss: 0.3422 - acc: 0.8377 - val_loss: 0.3378 - val_acc: 0.8386\n",
      "Epoch 26/100\n",
      "8/8 - 0s - loss: 0.3414 - acc: 0.8380 - val_loss: 0.3371 - val_acc: 0.8396\n",
      "Epoch 27/100\n",
      "8/8 - 0s - loss: 0.3398 - acc: 0.8385 - val_loss: 0.3371 - val_acc: 0.8394\n",
      "Epoch 28/100\n",
      "8/8 - 0s - loss: 0.3403 - acc: 0.8384 - val_loss: 0.3372 - val_acc: 0.8387\n",
      "Epoch 29/100\n",
      "8/8 - 0s - loss: 0.3415 - acc: 0.8400 - val_loss: 0.3374 - val_acc: 0.8391\n",
      "Epoch 30/100\n",
      "8/8 - 0s - loss: 0.3414 - acc: 0.8395 - val_loss: 0.3365 - val_acc: 0.8398\n",
      "Epoch 31/100\n",
      "8/8 - 0s - loss: 0.3379 - acc: 0.8399 - val_loss: 0.3363 - val_acc: 0.8402\n",
      "Epoch 32/100\n",
      "8/8 - 0s - loss: 0.3421 - acc: 0.8377 - val_loss: 0.3367 - val_acc: 0.8408\n",
      "Epoch 33/100\n",
      "8/8 - 0s - loss: 0.3394 - acc: 0.8401 - val_loss: 0.3362 - val_acc: 0.8403\n",
      "Epoch 34/100\n",
      "8/8 - 0s - loss: 0.3384 - acc: 0.8379 - val_loss: 0.3362 - val_acc: 0.8413\n",
      "Epoch 35/100\n",
      "8/8 - 0s - loss: 0.3375 - acc: 0.8412 - val_loss: 0.3360 - val_acc: 0.8400\n",
      "Epoch 36/100\n",
      "8/8 - 0s - loss: 0.3372 - acc: 0.8396 - val_loss: 0.3359 - val_acc: 0.8405\n",
      "Epoch 37/100\n",
      "8/8 - 0s - loss: 0.3360 - acc: 0.8409 - val_loss: 0.3358 - val_acc: 0.8404\n",
      "Epoch 38/100\n",
      "8/8 - 0s - loss: 0.3363 - acc: 0.8394 - val_loss: 0.3353 - val_acc: 0.8412\n",
      "Epoch 39/100\n",
      "8/8 - 0s - loss: 0.3377 - acc: 0.8412 - val_loss: 0.3354 - val_acc: 0.8412\n",
      "Epoch 40/100\n",
      "8/8 - 0s - loss: 0.3364 - acc: 0.8390 - val_loss: 0.3360 - val_acc: 0.8408\n",
      "Epoch 41/100\n",
      "8/8 - 0s - loss: 0.3373 - acc: 0.8397 - val_loss: 0.3355 - val_acc: 0.8405\n",
      "Epoch 42/100\n",
      "8/8 - 0s - loss: 0.3370 - acc: 0.8393 - val_loss: 0.3354 - val_acc: 0.8406\n",
      "Epoch 43/100\n",
      "8/8 - 0s - loss: 0.3347 - acc: 0.8419 - val_loss: 0.3353 - val_acc: 0.8413\n",
      "Epoch 44/100\n",
      "8/8 - 0s - loss: 0.3365 - acc: 0.8407 - val_loss: 0.3346 - val_acc: 0.8421\n",
      "Epoch 45/100\n",
      "8/8 - 0s - loss: 0.3349 - acc: 0.8415 - val_loss: 0.3348 - val_acc: 0.8413\n",
      "Epoch 46/100\n",
      "8/8 - 0s - loss: 0.3356 - acc: 0.8412 - val_loss: 0.3347 - val_acc: 0.8418\n",
      "Epoch 47/100\n",
      "8/8 - 0s - loss: 0.3338 - acc: 0.8411 - val_loss: 0.3349 - val_acc: 0.8413\n",
      "Epoch 48/100\n",
      "8/8 - 0s - loss: 0.3342 - acc: 0.8417 - val_loss: 0.3343 - val_acc: 0.8425\n",
      "Epoch 49/100\n",
      "8/8 - 0s - loss: 0.3348 - acc: 0.8407 - val_loss: 0.3344 - val_acc: 0.8415\n",
      "Epoch 50/100\n",
      "8/8 - 0s - loss: 0.3323 - acc: 0.8415 - val_loss: 0.3346 - val_acc: 0.8413\n",
      "Epoch 51/100\n",
      "8/8 - 0s - loss: 0.3342 - acc: 0.8389 - val_loss: 0.3340 - val_acc: 0.8422\n",
      "Epoch 52/100\n",
      "8/8 - 0s - loss: 0.3337 - acc: 0.8421 - val_loss: 0.3340 - val_acc: 0.8421\n",
      "Epoch 53/100\n",
      "8/8 - 0s - loss: 0.3323 - acc: 0.8434 - val_loss: 0.3344 - val_acc: 0.8413\n",
      "Epoch 54/100\n",
      "8/8 - 0s - loss: 0.3335 - acc: 0.8416 - val_loss: 0.3342 - val_acc: 0.8433\n",
      "Epoch 55/100\n",
      "8/8 - 0s - loss: 0.3330 - acc: 0.8407 - val_loss: 0.3341 - val_acc: 0.8426\n",
      "Epoch 56/100\n",
      "8/8 - 0s - loss: 0.3324 - acc: 0.8416 - val_loss: 0.3343 - val_acc: 0.8419\n",
      "Epoch 57/100\n",
      "8/8 - 0s - loss: 0.3314 - acc: 0.8431 - val_loss: 0.3340 - val_acc: 0.8419\n",
      "Epoch 58/100\n",
      "8/8 - 0s - loss: 0.3326 - acc: 0.8425 - val_loss: 0.3343 - val_acc: 0.8422\n",
      "Epoch 59/100\n",
      "8/8 - 0s - loss: 0.3324 - acc: 0.8428 - val_loss: 0.3343 - val_acc: 0.8420\n",
      "Epoch 60/100\n",
      "8/8 - 0s - loss: 0.3309 - acc: 0.8418 - val_loss: 0.3341 - val_acc: 0.8423\n",
      "Epoch 61/100\n",
      "8/8 - 0s - loss: 0.3308 - acc: 0.8435 - val_loss: 0.3339 - val_acc: 0.8426\n",
      "Epoch 62/100\n",
      "8/8 - 0s - loss: 0.3305 - acc: 0.8421 - val_loss: 0.3340 - val_acc: 0.8417\n",
      "Epoch 63/100\n",
      "8/8 - 0s - loss: 0.3307 - acc: 0.8427 - val_loss: 0.3334 - val_acc: 0.8421\n",
      "Epoch 64/100\n",
      "8/8 - 0s - loss: 0.3327 - acc: 0.8419 - val_loss: 0.3342 - val_acc: 0.8426\n",
      "Epoch 65/100\n",
      "8/8 - 0s - loss: 0.3301 - acc: 0.8440 - val_loss: 0.3338 - val_acc: 0.8426\n",
      "Epoch 66/100\n",
      "8/8 - 0s - loss: 0.3299 - acc: 0.8425 - val_loss: 0.3340 - val_acc: 0.8428\n",
      "Epoch 67/100\n",
      "8/8 - 0s - loss: 0.3302 - acc: 0.8422 - val_loss: 0.3343 - val_acc: 0.8425\n",
      "Epoch 68/100\n",
      "8/8 - 0s - loss: 0.3296 - acc: 0.8427 - val_loss: 0.3342 - val_acc: 0.8417\n",
      "Epoch 69/100\n",
      "8/8 - 0s - loss: 0.3294 - acc: 0.8423 - val_loss: 0.3341 - val_acc: 0.8421\n",
      "Epoch 70/100\n",
      "8/8 - 0s - loss: 0.3284 - acc: 0.8440 - val_loss: 0.3340 - val_acc: 0.8422\n",
      "Epoch 71/100\n",
      "8/8 - 0s - loss: 0.3294 - acc: 0.8448 - val_loss: 0.3342 - val_acc: 0.8419\n",
      "Epoch 72/100\n",
      "8/8 - 0s - loss: 0.3276 - acc: 0.8440 - val_loss: 0.3343 - val_acc: 0.8421\n",
      "Epoch 73/100\n",
      "8/8 - 0s - loss: 0.3275 - acc: 0.8446 - val_loss: 0.3338 - val_acc: 0.8430\n",
      "Epoch 74/100\n",
      "8/8 - 0s - loss: 0.3271 - acc: 0.8442 - val_loss: 0.3343 - val_acc: 0.8419\n",
      "Epoch 75/100\n",
      "8/8 - 0s - loss: 0.3277 - acc: 0.8448 - val_loss: 0.3340 - val_acc: 0.8438\n",
      "Epoch 76/100\n",
      "8/8 - 0s - loss: 0.3279 - acc: 0.8451 - val_loss: 0.3338 - val_acc: 0.8435\n",
      "Epoch 77/100\n",
      "8/8 - 0s - loss: 0.3277 - acc: 0.8451 - val_loss: 0.3339 - val_acc: 0.8436\n",
      "Epoch 78/100\n",
      "8/8 - 0s - loss: 0.3273 - acc: 0.8436 - val_loss: 0.3338 - val_acc: 0.8437\n",
      "Epoch 79/100\n",
      "8/8 - 0s - loss: 0.3306 - acc: 0.8446 - val_loss: 0.3338 - val_acc: 0.8440\n",
      "Epoch 80/100\n",
      "8/8 - 0s - loss: 0.3290 - acc: 0.8429 - val_loss: 0.3339 - val_acc: 0.8436\n",
      "Epoch 81/100\n",
      "8/8 - 0s - loss: 0.3284 - acc: 0.8441 - val_loss: 0.3337 - val_acc: 0.8430\n",
      "Epoch 82/100\n",
      "8/8 - 0s - loss: 0.3278 - acc: 0.8455 - val_loss: 0.3340 - val_acc: 0.8423\n",
      "Epoch 83/100\n",
      "8/8 - 0s - loss: 0.3259 - acc: 0.8447 - val_loss: 0.3338 - val_acc: 0.8436\n",
      "Epoch 84/100\n",
      "8/8 - 0s - loss: 0.3272 - acc: 0.8440 - val_loss: 0.3340 - val_acc: 0.8430\n",
      "Epoch 85/100\n",
      "8/8 - 0s - loss: 0.3260 - acc: 0.8436 - val_loss: 0.3339 - val_acc: 0.8426\n",
      "Epoch 86/100\n",
      "8/8 - 0s - loss: 0.3266 - acc: 0.8442 - val_loss: 0.3338 - val_acc: 0.8428\n",
      "Epoch 87/100\n",
      "8/8 - 0s - loss: 0.3263 - acc: 0.8451 - val_loss: 0.3333 - val_acc: 0.8426\n",
      "Epoch 88/100\n",
      "8/8 - 0s - loss: 0.3260 - acc: 0.8458 - val_loss: 0.3335 - val_acc: 0.8433\n",
      "Epoch 89/100\n",
      "8/8 - 0s - loss: 0.3259 - acc: 0.8458 - val_loss: 0.3338 - val_acc: 0.8441\n",
      "Epoch 90/100\n",
      "8/8 - 0s - loss: 0.3251 - acc: 0.8441 - val_loss: 0.3337 - val_acc: 0.8434\n",
      "Epoch 91/100\n",
      "8/8 - 0s - loss: 0.3239 - acc: 0.8454 - val_loss: 0.3337 - val_acc: 0.8440\n",
      "Epoch 92/100\n",
      "8/8 - 0s - loss: 0.3262 - acc: 0.8452 - val_loss: 0.3337 - val_acc: 0.8440\n",
      "Epoch 93/100\n",
      "8/8 - 0s - loss: 0.3257 - acc: 0.8433 - val_loss: 0.3338 - val_acc: 0.8437\n",
      "Epoch 94/100\n",
      "8/8 - 0s - loss: 0.3250 - acc: 0.8447 - val_loss: 0.3341 - val_acc: 0.8439\n",
      "Epoch 95/100\n",
      "8/8 - 0s - loss: 0.3230 - acc: 0.8464 - val_loss: 0.3337 - val_acc: 0.8438\n",
      "Epoch 96/100\n",
      "8/8 - 0s - loss: 0.3261 - acc: 0.8451 - val_loss: 0.3332 - val_acc: 0.8434\n",
      "Epoch 97/100\n",
      "8/8 - 0s - loss: 0.3236 - acc: 0.8449 - val_loss: 0.3338 - val_acc: 0.8437\n",
      "Epoch 98/100\n",
      "8/8 - 0s - loss: 0.3233 - acc: 0.8458 - val_loss: 0.3340 - val_acc: 0.8444\n",
      "Epoch 99/100\n",
      "8/8 - 0s - loss: 0.3238 - acc: 0.8449 - val_loss: 0.3335 - val_acc: 0.8447\n",
      "Epoch 100/100\n",
      "8/8 - 0s - loss: 0.3236 - acc: 0.8460 - val_loss: 0.3334 - val_acc: 0.8441\n"
     ]
    }
   ],
   "source": [
    "results_dropout = model_dropout.fit(X_train_sc, y_train,\n",
    "                                   validation_data=(X_test_sc, y_test),\n",
    "                                   batch_size=5000,\n",
    "                                   epochs=100,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_features=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=2)\n",
    "rf.fit(X_train,y_train)\n",
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9372966666666667 0.88232\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500, max_depth=30, min_samples_leaf=2, bootstrap=True)\n",
    "rf.fit(X_train_sc,y_train)\n",
    "print(rf.score(X_train_sc, y_train), rf.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=3, bootstrap=False)\n",
    "rf.fit(X_train,y_train)\n",
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with cvec vectorizer and Random Forest\n",
    "pipe_gbc = Pipeline([\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params and grid search \n",
    "gbc_params = {\n",
    "    'gb__n_estimators': [25, 50, 100],\n",
    "    'gb__max_depth' : [3,4,5],\n",
    "    'gb__learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "gs_gbc = GridSearchCV(pipe_gbc, param_grid = gbc_params, cv=5)\n",
    "gs_gbc.fit(X_train_sc, y_train)\n",
    "print(f' Best Score from Grid Search is {gs_gbc.best_score_}')\n",
    "gs_gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions \n",
    "preds_gb = gs_gbc.predict(X_test)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_gb)\n",
    "ConfusionMatrixDisplay(cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=300, learning_rate )\n",
    "gb.fit(X_train_sc, y_train_sc)\n",
    "print(gb.score(X_train, y_train), gb.score(X_test, y_test),  \n",
    "      cross_val_score(gb, X_train_sc, y_train_sc, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions \n",
    "preds_gb = gb.predict(X_test)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_gb)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['0','1','2','3']).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'importance' : gb.feature_importances_, 'feature_names' : X_train.columns}).sort_values(by='importance', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2 = GradientBoostingClassifier(n_estimators=500)\n",
    "gb2.fit(X_train, y_train)\n",
    "print(gb2.score(X_train, y_train), gb2.score(X_test, y_test),  \n",
    "      cross_val_score(gb2, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb3 = GradientBoostingClassifier(n_estimators=500, \n",
    "                        min_samples_split = 100, \n",
    "                        min_samples_leaf = 50, \n",
    "                        max_depth=8,\n",
    "                        max_features='sqrt',\n",
    "                        subsample=0.8)\n",
    "gb3.fit(X_train, y_train)\n",
    "print(gb3.score(X_train, y_train), gb3.score(X_test, y_test),  \n",
    "      cross_val_score(gb3, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
