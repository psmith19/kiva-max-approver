{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva = pd.read_csv('kivasmall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419156, 28)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables of interest: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORIGINAL_LANGUAGE</th>\n",
       "      <th>LOAN_AMOUNT</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ACTIVITY_NAME</th>\n",
       "      <th>SECTOR_NAME</th>\n",
       "      <th>COUNTRY_CODE</th>\n",
       "      <th>LENDER_TERM</th>\n",
       "      <th>REPAYMENT_INTERVAL</th>\n",
       "      <th>DISTRIBUTION_MODEL</th>\n",
       "      <th>word_count_DT</th>\n",
       "      <th>...</th>\n",
       "      <th>PIC_TRUE_COUNT</th>\n",
       "      <th>PIC_FALSE_COUNT</th>\n",
       "      <th>ANY_FEM</th>\n",
       "      <th>ANY_MALE</th>\n",
       "      <th>word_char_DT</th>\n",
       "      <th>word_char_TAGS</th>\n",
       "      <th>word_char_LU</th>\n",
       "      <th>MALE_FEM</th>\n",
       "      <th>MALE_PIC</th>\n",
       "      <th>FEM_PIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>1</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>Health</td>\n",
       "      <td>EC</td>\n",
       "      <td>6.0</td>\n",
       "      <td>monthly</td>\n",
       "      <td>field_partner</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177408</td>\n",
       "      <td>180</td>\n",
       "      <td>104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Personal Products Sales</td>\n",
       "      <td>Retail</td>\n",
       "      <td>PH</td>\n",
       "      <td>14.0</td>\n",
       "      <td>monthly</td>\n",
       "      <td>field_partner</td>\n",
       "      <td>75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27825</td>\n",
       "      <td>84</td>\n",
       "      <td>828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORIGINAL_LANGUAGE  LOAN_AMOUNT  STATUS            ACTIVITY_NAME SECTOR_NAME  \\\n",
       "0           Spanish       1075.0       1            miscellaneous      Health   \n",
       "1           English        400.0       0  Personal Products Sales      Retail   \n",
       "\n",
       "  COUNTRY_CODE  LENDER_TERM REPAYMENT_INTERVAL DISTRIBUTION_MODEL  \\\n",
       "0           EC          6.0            monthly      field_partner   \n",
       "1           PH         14.0            monthly      field_partner   \n",
       "\n",
       "   word_count_DT  ...  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
       "0            192  ...             1.0              0.0      1.0       1.0   \n",
       "1             75  ...             1.0              0.0      1.0       1.0   \n",
       "\n",
       "   word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM  MALE_PIC  FEM_PIC  \n",
       "0        177408             180           104       1.0       1.0      1.0  \n",
       "1         27825              84           828       1.0       1.0      1.0  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE     3239\n",
       "LOAN_AMOUNT              0\n",
       "STATUS                   0\n",
       "ACTIVITY_NAME            0\n",
       "SECTOR_NAME              0\n",
       "COUNTRY_CODE             0\n",
       "LENDER_TERM              0\n",
       "REPAYMENT_INTERVAL       0\n",
       "DISTRIBUTION_MODEL       0\n",
       "word_count_DT            0\n",
       "word_count_TAGS          0\n",
       "word_count_LU            0\n",
       "char_count_DT            0\n",
       "char_count_TAGS          0\n",
       "char_count_LU            0\n",
       "month                    0\n",
       "FEM_COUNT             3239\n",
       "MALE_COUNT            3239\n",
       "PIC_TRUE_COUNT        3239\n",
       "PIC_FALSE_COUNT       3239\n",
       "ANY_FEM               3239\n",
       "ANY_MALE              3239\n",
       "word_char_DT             0\n",
       "word_char_TAGS           0\n",
       "word_char_LU             0\n",
       "MALE_FEM              3239\n",
       "MALE_PIC              3239\n",
       "FEM_PIC               3239\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = {'ORIGINAL_LANGUAGE' : 'MISSING', 'FEM_COUNT' : 0, 'MALE_COUNT' : 0,'PIC_TRUE_COUNT' : 0, 'PIC_FALSE_COUNT' : 0,'ANY_FEM' : 0,'ANY_MALE' : 0,'COUNTRY_CODE':'MISSING', 'MALE_FEM':0,'MALE_PIC':0,'FEM_PIC':0}\n",
    "kiva .fillna(value = fill_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE     0\n",
       "LOAN_AMOUNT           0\n",
       "STATUS                0\n",
       "ACTIVITY_NAME         0\n",
       "SECTOR_NAME           0\n",
       "COUNTRY_CODE          0\n",
       "LENDER_TERM           0\n",
       "REPAYMENT_INTERVAL    0\n",
       "DISTRIBUTION_MODEL    0\n",
       "word_count_DT         0\n",
       "word_count_TAGS       0\n",
       "word_count_LU         0\n",
       "char_count_DT         0\n",
       "char_count_TAGS       0\n",
       "char_count_LU         0\n",
       "month                 0\n",
       "FEM_COUNT             0\n",
       "MALE_COUNT            0\n",
       "PIC_TRUE_COUNT        0\n",
       "PIC_FALSE_COUNT       0\n",
       "ANY_FEM               0\n",
       "ANY_MALE              0\n",
       "word_char_DT          0\n",
       "word_char_TAGS        0\n",
       "word_char_LU          0\n",
       "MALE_FEM              0\n",
       "MALE_PIC              0\n",
       "FEM_PIC               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ORIGINAL_LANGUAGE', 'LOAN_AMOUNT', 'STATUS', 'ACTIVITY_NAME',\n",
       "       'SECTOR_NAME', 'COUNTRY_CODE', 'LENDER_TERM', 'REPAYMENT_INTERVAL',\n",
       "       'DISTRIBUTION_MODEL', 'word_count_DT', 'word_count_TAGS',\n",
       "       'word_count_LU', 'char_count_DT', 'char_count_TAGS', 'char_count_LU',\n",
       "       'month', 'FEM_COUNT', 'MALE_COUNT', 'PIC_TRUE_COUNT', 'PIC_FALSE_COUNT',\n",
       "       'ANY_FEM', 'ANY_MALE', 'word_char_DT', 'word_char_TAGS', 'word_char_LU',\n",
       "       'MALE_FEM', 'MALE_PIC', 'FEM_PIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGINAL_LANGUAGE      object\n",
       "LOAN_AMOUNT           float64\n",
       "STATUS                  int64\n",
       "ACTIVITY_NAME          object\n",
       "SECTOR_NAME            object\n",
       "COUNTRY_CODE           object\n",
       "LENDER_TERM           float64\n",
       "REPAYMENT_INTERVAL     object\n",
       "DISTRIBUTION_MODEL     object\n",
       "word_count_DT           int64\n",
       "word_count_TAGS         int64\n",
       "word_count_LU           int64\n",
       "char_count_DT           int64\n",
       "char_count_TAGS         int64\n",
       "char_count_LU           int64\n",
       "month                   int64\n",
       "FEM_COUNT             float64\n",
       "MALE_COUNT            float64\n",
       "PIC_TRUE_COUNT        float64\n",
       "PIC_FALSE_COUNT       float64\n",
       "ANY_FEM               float64\n",
       "ANY_MALE              float64\n",
       "word_char_DT            int64\n",
       "word_char_TAGS          int64\n",
       "word_char_LU            int64\n",
       "MALE_FEM              float64\n",
       "MALE_PIC              float64\n",
       "FEM_PIC               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419156, 28)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                count      mean\n",
      "ACTIVITY_NAME                                  \n",
      "Agriculture                     13298  0.782448\n",
      "Animal Sales                     4589  0.818261\n",
      "Bakery                           2328  0.848797\n",
      "Beauty Salon                     4978  0.758939\n",
      "Beverages                        2152  0.811338\n",
      "Cattle                           7205  0.703678\n",
      "Cereals                          5788  0.805114\n",
      "Charcoal Sales                   2414  0.905965\n",
      "Clothing                         2095  0.783294\n",
      "Clothing Sales                  14808  0.768368\n",
      "Cosmetics Sales                  2950  0.734237\n",
      "Crafts                           2266  0.967785\n",
      "Dairy                            5783  0.849905\n",
      "Education provider               2679  0.947368\n",
      "Farm Supplies                    2015  0.769231\n",
      "Farming                         50607  0.806884\n",
      "Fish Selling                     7383  0.911824\n",
      "Fishing                          4828  0.942005\n",
      "Food                             6530  0.824809\n",
      "Food Market                      4075  0.874847\n",
      "Food Production/Sales           17794  0.844105\n",
      "Food Stall                       4812  0.870116\n",
      "Fruits & Vegetables              9558  0.881879\n",
      "General Store                   37062  0.828908\n",
      "Grocery Store                    9853  0.824520\n",
      "Higher education costs           9576  0.947473\n",
      "Home Appliances                 11534  0.988729\n",
      "Home Energy                      4790  0.972860\n",
      "Home Products Sales              2392  0.769649\n",
      "Livestock                        8015  0.776544\n",
      "Motorcycle Transport             4272  0.675562\n",
      "Personal Expenses                4211  0.844455\n",
      "Personal Housing Expenses       24777  0.855874\n",
      "Personal Medical Expenses        5818  0.740289\n",
      "Personal Products Sales          2355  0.793206\n",
      "Pigs                            15960  0.944048\n",
      "Poultry                          6365  0.898193\n",
      "Primary/secondary school costs   5158  0.965297\n",
      "Restaurant                       3026  0.799075\n",
      "Retail                          15803  0.765234\n",
      "Services                         4605  0.644083\n",
      "Sewing                           4688  0.909770\n",
      "Tailoring                        6856  0.897754\n",
      "Transportation                   2242  0.740410\n",
      "Used Clothing                    2878  0.888117\n",
      "Weaving                          2076  0.999037\n",
      "miscellaneous                   43909  0.808969\n",
      "                 count      mean\n",
      "SECTOR_NAME                     \n",
      "Agriculture     114884  0.822543\n",
      "Arts              7934  0.969750\n",
      "Clothing         20250  0.789975\n",
      "Construction      3809  0.847204\n",
      "Education        17738  0.953490\n",
      "Entertainment      495  0.707071\n",
      "Food             83125  0.849672\n",
      "Health            7923  0.780386\n",
      "Housing          25683  0.849122\n",
      "Manufacturing     3182  0.992458\n",
      "Personal Use     22092  0.932419\n",
      "Retail           73695  0.803867\n",
      "Services         28195  0.797553\n",
      "Transportation    9821  0.705122\n",
      "Wholesale          330  0.884848\n",
      "               count      mean\n",
      "COUNTRY_CODE                  \n",
      "AL              1436  0.638579\n",
      "AM              5072  0.544558\n",
      "BF              1853  0.967080\n",
      "BO              4333  0.690976\n",
      "CD              1862  0.896348\n",
      "CM              1378  0.873730\n",
      "CO             18590  0.644540\n",
      "CR              1093  0.779506\n",
      "EC             10678  0.902978\n",
      "EG              1599  0.974359\n",
      "GE              1567  0.867262\n",
      "GH              3281  0.917098\n",
      "GT              4061  0.848806\n",
      "HN              4075  0.817423\n",
      "HT              2291  0.960279\n",
      "ID              3185  0.862166\n",
      "IN              7672  0.983186\n",
      "JO              2998  0.742829\n",
      "KE             51170  0.784659\n",
      "KG              4402  0.667197\n",
      "KH             19196  0.897739\n",
      "LB              8658  0.773851\n",
      "LR              3280  0.999695\n",
      "MG              4369  0.999771\n",
      "ML              1999  0.751876\n",
      "MM              1620  0.727778\n",
      "MX              3103  0.773445\n",
      "MZ              2278  0.786216\n",
      "NG              5379  0.807399\n",
      "NI              5916  0.793272\n",
      "PE             11180  0.915027\n",
      "PH             88691  0.963300\n",
      "PK             14394  0.874045\n",
      "PS              5057  0.739767\n",
      "PY              6839  0.934201\n",
      "RW              4258  0.688116\n",
      "SL              2750  0.856364\n",
      "SN              1915  0.889817\n",
      "SV             21840  0.691346\n",
      "TG              3980  0.990955\n",
      "TJ             14189  0.793079\n",
      "TL              2439  0.789668\n",
      "TZ              5026  0.796458\n",
      "UG             16998  0.720144\n",
      "US              4604  0.422459\n",
      "VN              7564  0.866208\n",
      "WS              5763  0.684019\n",
      "ZW              2607  0.949367\n",
      "miscellaneous  10668  0.885171\n",
      "                     count      mean\n",
      "REPAYMENT_INTERVAL                  \n",
      "bullet               42149  0.787350\n",
      "irregular            18397  0.774365\n",
      "monthly             358610  0.843724\n",
      "                     count      mean\n",
      "DISTRIBUTION_MODEL                  \n",
      "direct                5306  0.515831\n",
      "field_partner       413850  0.839104\n",
      "       count      mean\n",
      "month                 \n",
      "0      37934  0.810065\n",
      "1      67612  0.841271\n",
      "2      62742  0.900704\n",
      "3      36891  0.874576\n",
      "4      34333  0.822620\n",
      "5      38448  0.786205\n",
      "6      35590  0.806378\n",
      "7      37160  0.774919\n",
      "8      33815  0.838681\n",
      "9      34631  0.845745\n"
     ]
    }
   ],
   "source": [
    "catcols = ['ORIGINAL_LANGUAGE', 'ACTIVITY_NAME', 'SECTOR_NAME', 'COUNTRY_CODE', 'REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'month']\n",
    "\n",
    "for i in range(1,len(catcols)):\n",
    "    print(kiva.groupby(catcols[i], dropna=False)['STATUS'].agg(['count', 'mean']))\n",
    "    #print(pd.pivot_table(df, columns = totcols[i], aggfunc=np.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva_dummies = pd.get_dummies(kiva, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419156, 138)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva_dummies_small = kiva_dummies.sample(400_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    334065\n",
       "0     65935\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva_dummies_small['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating X, y and test-train split\n",
    "X = kiva_dummies_small.drop(columns = ['STATUS'])\n",
    "y = kiva_dummies_small['STATUS']\n",
    "\n",
    "#Perform test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42, stratify=y)\n",
    "\n",
    "#Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building out logistic regressoin with higher max-iter\n",
    "logreg = LogisticRegression(solver='liblinear', max_iter=1200)\n",
    "logreg.fit(X_train_sc, y_train)\n",
    "print(logreg.score(X_train_sc,y_train), logreg.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefficients</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.616965</td>\n",
       "      <td>char_count_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.614421</td>\n",
       "      <td>word_count_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.786561</td>\n",
       "      <td>COUNTRY_CODE_MG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.651632</td>\n",
       "      <td>FEM_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0.631578</td>\n",
       "      <td>COUNTRY_CODE_LR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.604709</td>\n",
       "      <td>LENDER_TERM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.603199</td>\n",
       "      <td>LOAN_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.555922</td>\n",
       "      <td>SECTOR_NAME_Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.543317</td>\n",
       "      <td>char_count_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.457672</td>\n",
       "      <td>word_count_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.429481</td>\n",
       "      <td>ANY_FEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.414231</td>\n",
       "      <td>ACTIVITY_NAME_Renewable Energy Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.390580</td>\n",
       "      <td>COUNTRY_CODE_LA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-0.373425</td>\n",
       "      <td>COUNTRY_CODE_KE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.347891</td>\n",
       "      <td>ACTIVITY_NAME_Sewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.345024</td>\n",
       "      <td>ACTIVITY_NAME_Tailoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.337741</td>\n",
       "      <td>COUNTRY_CODE_TR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.291652</td>\n",
       "      <td>char_count_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0.289911</td>\n",
       "      <td>COUNTRY_CODE_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.283003</td>\n",
       "      <td>ACTIVITY_NAME_Weaving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.271139</td>\n",
       "      <td>SECTOR_NAME_Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.269929</td>\n",
       "      <td>PIC_TRUE_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.264036</td>\n",
       "      <td>word_count_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.263039</td>\n",
       "      <td>ACTIVITY_NAME_Higher education costs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.255220</td>\n",
       "      <td>ORIGINAL_LANGUAGE_MISSING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     coefficients                                 features\n",
       "6        1.616965                          char_count_TAGS\n",
       "3       -1.614421                          word_count_TAGS\n",
       "234      0.786561                          COUNTRY_CODE_MG\n",
       "9        0.651632                                FEM_COUNT\n",
       "231      0.631578                          COUNTRY_CODE_LR\n",
       "1       -0.604709                              LENDER_TERM\n",
       "0       -0.603199                              LOAN_AMOUNT\n",
       "193     -0.555922                     SECTOR_NAME_Services\n",
       "5        0.543317                            char_count_DT\n",
       "2       -0.457672                            word_count_DT\n",
       "13       0.429481                                  ANY_FEM\n",
       "150      0.414231  ACTIVITY_NAME_Renewable Energy Products\n",
       "229      0.390580                          COUNTRY_CODE_LA\n",
       "226     -0.373425                          COUNTRY_CODE_KE\n",
       "156      0.347891                     ACTIVITY_NAME_Sewing\n",
       "161      0.345024                  ACTIVITY_NAME_Tailoring\n",
       "266      0.337741                          COUNTRY_CODE_TR\n",
       "7       -0.291652                            char_count_LU\n",
       "223      0.289911                          COUNTRY_CODE_IN\n",
       "178      0.283003                    ACTIVITY_NAME_Weaving\n",
       "185      0.271139                    SECTOR_NAME_Education\n",
       "11      -0.269929                           PIC_TRUE_COUNT\n",
       "4        0.264036                            word_count_LU\n",
       "96       0.263039     ACTIVITY_NAME_Higher education costs\n",
       "16       0.255220                ORIGINAL_LANGUAGE_MISSING"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See what coefficients came out strong\n",
    "coef= logreg.coef_[0]\n",
    "coef_df = pd.DataFrame({'coefficients': coef, 'features': X_train.columns}).sort_values(by = 'coefficients', ascending = False, key = abs).head(25)\n",
    "coef_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get predictions \n",
    "preds = logreg.predict(X_test)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "ConfusionMatrixDisplay(cm).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Various scores:  AUROC: 0.6133917892649143, ACC_SCORE: 0.3992823529411765, REC_SCORE: 0.2651464374180388, PREC_SCORE: 0.9666401062416998,F1: 0.4161454462294895\n"
     ]
    }
   ],
   "source": [
    "print(f'Various scores:  AUROC: {roc_auc_score(y_test, preds)}, ACC_SCORE: {accuracy_score(y_test, preds)}, REC_SCORE: {recall_score(y_test, preds)}, PREC_SCORE: {precision_score(y_test, preds)},F1: {f1_score(y_test, preds)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of the model classes to test\n",
    "model_list = [\n",
    "    #LogisticRegression(),\n",
    "    #DecisionTreeClassifier(),\n",
    "    #BaggingClassifier(),\n",
    "    RandomForestClassifier()\n",
    "    #ExtraTreesClassifier(),\n",
    "    #AdaBoostClassifier(),\n",
    "    #GradientBoostingClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list to store each model's results in a dictionary\n",
    "classifier_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "\n",
    "    #fit the model\n",
    "    model.fit(X_train_sc, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train_sc, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test_sc, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train_sc, y_train, cv = 5).mean()\n",
    "        \n",
    "    #add the dictionary to the list\n",
    "    classifier_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.864153</td>\n",
       "      <td>0.863718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  train_score  test_score  cv_score\n",
       "0  RandomForestClassifier()     0.999992    0.864153  0.863718"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get just RF model scores\n",
    "clf_results = pd.DataFrame(classifier_list)\n",
    "clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.86312</td>\n",
       "      <td>0.861067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.849187</td>\n",
       "      <td>0.84690</td>\n",
       "      <td>0.848207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  train_score  test_score  cv_score\n",
       "0      RandomForestClassifier()     0.999993     0.86312  0.861067\n",
       "1  GradientBoostingClassifier()     0.849187     0.84690  0.848207"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_results = pd.DataFrame(classifier_list)\n",
    "clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.852340</td>\n",
       "      <td>0.85158</td>\n",
       "      <td>0.852060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.85248</td>\n",
       "      <td>0.850940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>0.965067</td>\n",
       "      <td>0.86543</td>\n",
       "      <td>0.864090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.971033</td>\n",
       "      <td>0.87157</td>\n",
       "      <td>0.872913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesClassifier()</td>\n",
       "      <td>0.971040</td>\n",
       "      <td>0.86230</td>\n",
       "      <td>0.861563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.861270</td>\n",
       "      <td>0.86063</td>\n",
       "      <td>0.861053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.865297</td>\n",
       "      <td>0.86416</td>\n",
       "      <td>0.864963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model_name  train_score  test_score  cv_score\n",
       "0          LogisticRegression()     0.852340     0.85158  0.852060\n",
       "1      DecisionTreeClassifier()     0.971040     0.85248  0.850940\n",
       "2           BaggingClassifier()     0.965067     0.86543  0.864090\n",
       "3      RandomForestClassifier()     0.971033     0.87157  0.872913\n",
       "4        ExtraTreesClassifier()     0.971040     0.86230  0.861563\n",
       "5          AdaBoostClassifier()     0.861270     0.86063  0.861053\n",
       "6  GradientBoostingClassifier()     0.865297     0.86416  0.864963"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Results before number of words and characters were added\n",
    "clf_results = pd.DataFrame(classifier_list)\n",
    "clf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 - 2s - loss: 0.8722 - acc: 0.5795 - val_loss: 0.4898 - val_acc: 0.8074\n",
      "Epoch 2/100\n",
      "28/28 - 1s - loss: 0.5199 - acc: 0.7926 - val_loss: 0.4229 - val_acc: 0.8115\n",
      "Epoch 3/100\n",
      "28/28 - 1s - loss: 0.4653 - acc: 0.7975 - val_loss: 0.3961 - val_acc: 0.8164\n",
      "Epoch 4/100\n",
      "28/28 - 1s - loss: 0.4362 - acc: 0.8061 - val_loss: 0.3833 - val_acc: 0.8223\n",
      "Epoch 5/100\n",
      "28/28 - 1s - loss: 0.4179 - acc: 0.8107 - val_loss: 0.3739 - val_acc: 0.8271\n",
      "Epoch 6/100\n",
      "28/28 - 1s - loss: 0.4048 - acc: 0.8157 - val_loss: 0.3669 - val_acc: 0.8293\n",
      "Epoch 7/100\n",
      "28/28 - 1s - loss: 0.3946 - acc: 0.8187 - val_loss: 0.3610 - val_acc: 0.8311\n",
      "Epoch 8/100\n",
      "28/28 - 1s - loss: 0.3853 - acc: 0.8221 - val_loss: 0.3560 - val_acc: 0.8336\n",
      "Epoch 9/100\n",
      "28/28 - 1s - loss: 0.3781 - acc: 0.8243 - val_loss: 0.3517 - val_acc: 0.8354\n",
      "Epoch 10/100\n",
      "28/28 - 1s - loss: 0.3718 - acc: 0.8276 - val_loss: 0.3477 - val_acc: 0.8367\n",
      "Epoch 11/100\n",
      "28/28 - 1s - loss: 0.3658 - acc: 0.8298 - val_loss: 0.3435 - val_acc: 0.8387\n",
      "Epoch 12/100\n",
      "28/28 - 1s - loss: 0.3609 - acc: 0.8321 - val_loss: 0.3401 - val_acc: 0.8402\n",
      "Epoch 13/100\n",
      "28/28 - 1s - loss: 0.3565 - acc: 0.8334 - val_loss: 0.3368 - val_acc: 0.8417\n",
      "Epoch 14/100\n",
      "28/28 - 1s - loss: 0.3530 - acc: 0.8353 - val_loss: 0.3338 - val_acc: 0.8431\n",
      "Epoch 15/100\n",
      "28/28 - 1s - loss: 0.3494 - acc: 0.8366 - val_loss: 0.3308 - val_acc: 0.8446\n",
      "Epoch 16/100\n",
      "28/28 - 1s - loss: 0.3466 - acc: 0.8373 - val_loss: 0.3281 - val_acc: 0.8458\n",
      "Epoch 17/100\n",
      "28/28 - 1s - loss: 0.3432 - acc: 0.8402 - val_loss: 0.3257 - val_acc: 0.8462\n",
      "Epoch 18/100\n",
      "28/28 - 1s - loss: 0.3402 - acc: 0.8414 - val_loss: 0.3236 - val_acc: 0.8472\n",
      "Epoch 19/100\n",
      "28/28 - 1s - loss: 0.3377 - acc: 0.8424 - val_loss: 0.3217 - val_acc: 0.8484\n",
      "Epoch 20/100\n",
      "28/28 - 1s - loss: 0.3362 - acc: 0.8436 - val_loss: 0.3202 - val_acc: 0.8487\n",
      "Epoch 21/100\n",
      "28/28 - 1s - loss: 0.3333 - acc: 0.8446 - val_loss: 0.3183 - val_acc: 0.8499\n",
      "Epoch 22/100\n",
      "28/28 - 1s - loss: 0.3312 - acc: 0.8452 - val_loss: 0.3169 - val_acc: 0.8502\n",
      "Epoch 23/100\n",
      "28/28 - 1s - loss: 0.3286 - acc: 0.8463 - val_loss: 0.3153 - val_acc: 0.8506\n",
      "Epoch 24/100\n",
      "28/28 - 1s - loss: 0.3281 - acc: 0.8462 - val_loss: 0.3143 - val_acc: 0.8510\n",
      "Epoch 25/100\n",
      "28/28 - 1s - loss: 0.3260 - acc: 0.8472 - val_loss: 0.3128 - val_acc: 0.8526\n",
      "Epoch 26/100\n",
      "28/28 - 1s - loss: 0.3249 - acc: 0.8480 - val_loss: 0.3116 - val_acc: 0.8529\n",
      "Epoch 27/100\n",
      "28/28 - 1s - loss: 0.3231 - acc: 0.8494 - val_loss: 0.3108 - val_acc: 0.8532\n",
      "Epoch 28/100\n",
      "28/28 - 1s - loss: 0.3214 - acc: 0.8501 - val_loss: 0.3097 - val_acc: 0.8538\n",
      "Epoch 29/100\n",
      "28/28 - 1s - loss: 0.3203 - acc: 0.8506 - val_loss: 0.3093 - val_acc: 0.8540\n",
      "Epoch 30/100\n",
      "28/28 - 1s - loss: 0.3195 - acc: 0.8512 - val_loss: 0.3083 - val_acc: 0.8550\n",
      "Epoch 31/100\n",
      "28/28 - 1s - loss: 0.3174 - acc: 0.8517 - val_loss: 0.3077 - val_acc: 0.8556\n",
      "Epoch 32/100\n",
      "28/28 - 1s - loss: 0.3176 - acc: 0.8519 - val_loss: 0.3070 - val_acc: 0.8564\n",
      "Epoch 33/100\n",
      "28/28 - 1s - loss: 0.3163 - acc: 0.8524 - val_loss: 0.3064 - val_acc: 0.8560\n",
      "Epoch 34/100\n",
      "28/28 - 1s - loss: 0.3157 - acc: 0.8528 - val_loss: 0.3054 - val_acc: 0.8565\n",
      "Epoch 35/100\n",
      "28/28 - 1s - loss: 0.3144 - acc: 0.8530 - val_loss: 0.3046 - val_acc: 0.8570\n",
      "Epoch 36/100\n",
      "28/28 - 1s - loss: 0.3137 - acc: 0.8534 - val_loss: 0.3048 - val_acc: 0.8569\n",
      "Epoch 37/100\n",
      "28/28 - 1s - loss: 0.3132 - acc: 0.8541 - val_loss: 0.3039 - val_acc: 0.8574\n",
      "Epoch 38/100\n",
      "28/28 - 1s - loss: 0.3117 - acc: 0.8544 - val_loss: 0.3032 - val_acc: 0.8574\n",
      "Epoch 39/100\n",
      "28/28 - 1s - loss: 0.3112 - acc: 0.8542 - val_loss: 0.3030 - val_acc: 0.8580\n",
      "Epoch 40/100\n",
      "28/28 - 1s - loss: 0.3106 - acc: 0.8545 - val_loss: 0.3023 - val_acc: 0.8585\n",
      "Epoch 41/100\n",
      "28/28 - 1s - loss: 0.3099 - acc: 0.8557 - val_loss: 0.3019 - val_acc: 0.8579\n",
      "Epoch 42/100\n",
      "28/28 - 1s - loss: 0.3089 - acc: 0.8560 - val_loss: 0.3014 - val_acc: 0.8593\n",
      "Epoch 43/100\n",
      "28/28 - 1s - loss: 0.3091 - acc: 0.8551 - val_loss: 0.3008 - val_acc: 0.8586\n",
      "Epoch 44/100\n",
      "28/28 - 1s - loss: 0.3073 - acc: 0.8568 - val_loss: 0.3006 - val_acc: 0.8593\n",
      "Epoch 45/100\n",
      "28/28 - 1s - loss: 0.3071 - acc: 0.8562 - val_loss: 0.3005 - val_acc: 0.8594\n",
      "Epoch 46/100\n",
      "28/28 - 1s - loss: 0.3069 - acc: 0.8565 - val_loss: 0.3004 - val_acc: 0.8588\n",
      "Epoch 47/100\n",
      "28/28 - 1s - loss: 0.3061 - acc: 0.8564 - val_loss: 0.2999 - val_acc: 0.8596\n",
      "Epoch 48/100\n",
      "28/28 - 1s - loss: 0.3059 - acc: 0.8569 - val_loss: 0.2992 - val_acc: 0.8596\n",
      "Epoch 49/100\n",
      "28/28 - 1s - loss: 0.3049 - acc: 0.8570 - val_loss: 0.2992 - val_acc: 0.8594\n",
      "Epoch 50/100\n",
      "28/28 - 1s - loss: 0.3047 - acc: 0.8572 - val_loss: 0.2992 - val_acc: 0.8591\n",
      "Epoch 51/100\n",
      "28/28 - 1s - loss: 0.3039 - acc: 0.8571 - val_loss: 0.2991 - val_acc: 0.8598\n",
      "Epoch 52/100\n",
      "28/28 - 1s - loss: 0.3041 - acc: 0.8571 - val_loss: 0.2987 - val_acc: 0.8601\n",
      "Epoch 53/100\n",
      "28/28 - 1s - loss: 0.3037 - acc: 0.8573 - val_loss: 0.2984 - val_acc: 0.8606\n",
      "Epoch 54/100\n",
      "28/28 - 1s - loss: 0.3022 - acc: 0.8580 - val_loss: 0.2981 - val_acc: 0.8598\n",
      "Epoch 55/100\n",
      "28/28 - 1s - loss: 0.3023 - acc: 0.8584 - val_loss: 0.2982 - val_acc: 0.8604\n",
      "Epoch 56/100\n",
      "28/28 - 1s - loss: 0.3021 - acc: 0.8578 - val_loss: 0.2979 - val_acc: 0.8604\n",
      "Epoch 57/100\n",
      "28/28 - 1s - loss: 0.3021 - acc: 0.8586 - val_loss: 0.2977 - val_acc: 0.8602\n",
      "Epoch 58/100\n",
      "28/28 - 1s - loss: 0.3015 - acc: 0.8584 - val_loss: 0.2976 - val_acc: 0.8604\n",
      "Epoch 59/100\n",
      "28/28 - 1s - loss: 0.3014 - acc: 0.8582 - val_loss: 0.2976 - val_acc: 0.8604\n",
      "Epoch 60/100\n",
      "28/28 - 1s - loss: 0.3006 - acc: 0.8589 - val_loss: 0.2977 - val_acc: 0.8600\n",
      "Epoch 61/100\n",
      "28/28 - 1s - loss: 0.2991 - acc: 0.8589 - val_loss: 0.2973 - val_acc: 0.8604\n",
      "Epoch 62/100\n",
      "28/28 - 1s - loss: 0.3001 - acc: 0.8590 - val_loss: 0.2971 - val_acc: 0.8602\n",
      "Epoch 63/100\n",
      "28/28 - 1s - loss: 0.2994 - acc: 0.8585 - val_loss: 0.2969 - val_acc: 0.8606\n",
      "Epoch 64/100\n",
      "28/28 - 1s - loss: 0.2991 - acc: 0.8589 - val_loss: 0.2972 - val_acc: 0.8611\n",
      "Epoch 65/100\n",
      "28/28 - 1s - loss: 0.2992 - acc: 0.8589 - val_loss: 0.2970 - val_acc: 0.8614\n",
      "Epoch 66/100\n",
      "28/28 - 1s - loss: 0.2988 - acc: 0.8596 - val_loss: 0.2972 - val_acc: 0.8606\n",
      "Epoch 67/100\n",
      "28/28 - 1s - loss: 0.2982 - acc: 0.8597 - val_loss: 0.2974 - val_acc: 0.8609\n",
      "Epoch 68/100\n",
      "28/28 - 1s - loss: 0.2986 - acc: 0.8590 - val_loss: 0.2971 - val_acc: 0.8612\n",
      "Epoch 69/100\n",
      "28/28 - 1s - loss: 0.2980 - acc: 0.8601 - val_loss: 0.2968 - val_acc: 0.8609\n",
      "Epoch 70/100\n",
      "28/28 - 1s - loss: 0.2981 - acc: 0.8595 - val_loss: 0.2971 - val_acc: 0.8613\n",
      "Epoch 71/100\n",
      "28/28 - 1s - loss: 0.2973 - acc: 0.8599 - val_loss: 0.2969 - val_acc: 0.8611\n",
      "Epoch 72/100\n",
      "28/28 - 1s - loss: 0.2973 - acc: 0.8598 - val_loss: 0.2971 - val_acc: 0.8618\n",
      "Epoch 73/100\n",
      "28/28 - 1s - loss: 0.2972 - acc: 0.8596 - val_loss: 0.2964 - val_acc: 0.8615\n",
      "Epoch 74/100\n",
      "28/28 - 1s - loss: 0.2961 - acc: 0.8603 - val_loss: 0.2966 - val_acc: 0.8618\n",
      "Epoch 75/100\n",
      "28/28 - 1s - loss: 0.2964 - acc: 0.8599 - val_loss: 0.2963 - val_acc: 0.8620\n",
      "Epoch 76/100\n",
      "28/28 - 1s - loss: 0.2960 - acc: 0.8604 - val_loss: 0.2965 - val_acc: 0.8619\n",
      "Epoch 77/100\n",
      "28/28 - 1s - loss: 0.2967 - acc: 0.8600 - val_loss: 0.2967 - val_acc: 0.8615\n",
      "Epoch 78/100\n",
      "28/28 - 1s - loss: 0.2957 - acc: 0.8599 - val_loss: 0.2968 - val_acc: 0.8618\n",
      "Epoch 79/100\n",
      "28/28 - 1s - loss: 0.2955 - acc: 0.8606 - val_loss: 0.2965 - val_acc: 0.8623\n",
      "Epoch 80/100\n",
      "28/28 - 1s - loss: 0.2951 - acc: 0.8608 - val_loss: 0.2969 - val_acc: 0.8621\n",
      "Epoch 81/100\n",
      "28/28 - 1s - loss: 0.2951 - acc: 0.8609 - val_loss: 0.2966 - val_acc: 0.8619\n",
      "Epoch 82/100\n",
      "28/28 - 1s - loss: 0.2954 - acc: 0.8606 - val_loss: 0.2967 - val_acc: 0.8623\n",
      "Epoch 83/100\n",
      "28/28 - 1s - loss: 0.2947 - acc: 0.8603 - val_loss: 0.2964 - val_acc: 0.8623\n",
      "Epoch 84/100\n",
      "28/28 - 1s - loss: 0.2947 - acc: 0.8606 - val_loss: 0.2964 - val_acc: 0.8624\n",
      "Epoch 85/100\n",
      "28/28 - 1s - loss: 0.2946 - acc: 0.8602 - val_loss: 0.2964 - val_acc: 0.8630\n",
      "Epoch 86/100\n",
      "28/28 - 1s - loss: 0.2944 - acc: 0.8608 - val_loss: 0.2966 - val_acc: 0.8626\n",
      "Epoch 87/100\n",
      "28/28 - 1s - loss: 0.2936 - acc: 0.8612 - val_loss: 0.2967 - val_acc: 0.8629\n",
      "Epoch 88/100\n",
      "28/28 - 1s - loss: 0.2937 - acc: 0.8611 - val_loss: 0.2965 - val_acc: 0.8623\n",
      "Epoch 89/100\n",
      "28/28 - 1s - loss: 0.2938 - acc: 0.8610 - val_loss: 0.2966 - val_acc: 0.8626\n",
      "Epoch 90/100\n",
      "28/28 - 1s - loss: 0.2940 - acc: 0.8614 - val_loss: 0.2966 - val_acc: 0.8628\n",
      "Epoch 91/100\n",
      "28/28 - 1s - loss: 0.2930 - acc: 0.8610 - val_loss: 0.2967 - val_acc: 0.8626\n",
      "Epoch 92/100\n",
      "28/28 - 1s - loss: 0.2939 - acc: 0.8610 - val_loss: 0.2965 - val_acc: 0.8625\n",
      "Epoch 93/100\n",
      "28/28 - 1s - loss: 0.2935 - acc: 0.8611 - val_loss: 0.2968 - val_acc: 0.8622\n",
      "Epoch 94/100\n",
      "28/28 - 1s - loss: 0.2927 - acc: 0.8611 - val_loss: 0.2965 - val_acc: 0.8627\n",
      "Epoch 95/100\n",
      "28/28 - 1s - loss: 0.2921 - acc: 0.8614 - val_loss: 0.2968 - val_acc: 0.8629\n",
      "Epoch 96/100\n",
      "28/28 - 1s - loss: 0.2927 - acc: 0.8616 - val_loss: 0.2966 - val_acc: 0.8627\n",
      "Epoch 97/100\n",
      "28/28 - 1s - loss: 0.2924 - acc: 0.8619 - val_loss: 0.2967 - val_acc: 0.8625\n",
      "Epoch 98/100\n",
      "28/28 - 1s - loss: 0.2928 - acc: 0.8614 - val_loss: 0.2970 - val_acc: 0.8624\n",
      "Epoch 99/100\n",
      "28/28 - 1s - loss: 0.2923 - acc: 0.8610 - val_loss: 0.2968 - val_acc: 0.8627\n",
      "Epoch 100/100\n",
      "28/28 - 1s - loss: 0.2911 - acc: 0.8623 - val_loss: 0.2968 - val_acc: 0.8628\n"
     ]
    }
   ],
   "source": [
    "# Build a model using Dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model_dropout = Sequential()\n",
    "\n",
    "#First layer\n",
    "model_dropout.add(Dense(64, activation='relu', input_shape=(X_train_sc.shape[1],)))\n",
    "model_dropout.add(Dropout(0.5))\n",
    "\n",
    "#Second layer\n",
    "model_dropout.add(Dense(64, activation='relu'))\n",
    "model_dropout.add(Dropout(0.5))\n",
    "\n",
    "#Output layer\n",
    "model_dropout.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#COmpile the model\n",
    "model_dropout.compile(loss='bce', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "results_dropout = model_dropout.fit(X_train_sc, y_train,\n",
    "                                   validation_data=(X_test_sc, y_test),\n",
    "                                   batch_size=9192,\n",
    "                                   epochs=100,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 - 1s - loss: 0.2920 - acc: 0.8619 - val_loss: 0.2973 - val_acc: 0.8630\n",
      "Epoch 2/100\n",
      "28/28 - 1s - loss: 0.2916 - acc: 0.8616 - val_loss: 0.2974 - val_acc: 0.8628\n",
      "Epoch 3/100\n",
      "28/28 - 1s - loss: 0.2913 - acc: 0.8621 - val_loss: 0.2967 - val_acc: 0.8633\n",
      "Epoch 4/100\n",
      "28/28 - 1s - loss: 0.2913 - acc: 0.8621 - val_loss: 0.2972 - val_acc: 0.8633\n",
      "Epoch 5/100\n",
      "28/28 - 1s - loss: 0.2912 - acc: 0.8624 - val_loss: 0.2974 - val_acc: 0.8631\n",
      "Epoch 6/100\n",
      "28/28 - 1s - loss: 0.2914 - acc: 0.8623 - val_loss: 0.2978 - val_acc: 0.8627\n",
      "Epoch 7/100\n",
      "28/28 - 1s - loss: 0.2911 - acc: 0.8623 - val_loss: 0.2972 - val_acc: 0.8629\n",
      "Epoch 8/100\n",
      "28/28 - 1s - loss: 0.2900 - acc: 0.8623 - val_loss: 0.2973 - val_acc: 0.8630\n",
      "Epoch 9/100\n",
      "28/28 - 1s - loss: 0.2907 - acc: 0.8630 - val_loss: 0.2974 - val_acc: 0.8636\n",
      "Epoch 10/100\n",
      "28/28 - 1s - loss: 0.2906 - acc: 0.8623 - val_loss: 0.2973 - val_acc: 0.8637\n",
      "Epoch 11/100\n",
      "28/28 - 1s - loss: 0.2907 - acc: 0.8621 - val_loss: 0.2975 - val_acc: 0.8635\n",
      "Epoch 12/100\n",
      "28/28 - 1s - loss: 0.2903 - acc: 0.8618 - val_loss: 0.2981 - val_acc: 0.8634\n",
      "Epoch 13/100\n",
      "28/28 - 1s - loss: 0.2905 - acc: 0.8621 - val_loss: 0.2980 - val_acc: 0.8637\n",
      "Epoch 14/100\n",
      "28/28 - 1s - loss: 0.2900 - acc: 0.8620 - val_loss: 0.2976 - val_acc: 0.8640\n",
      "Epoch 15/100\n",
      "28/28 - 1s - loss: 0.2897 - acc: 0.8628 - val_loss: 0.2980 - val_acc: 0.8631\n",
      "Epoch 16/100\n",
      "28/28 - 1s - loss: 0.2890 - acc: 0.8627 - val_loss: 0.2979 - val_acc: 0.8633\n",
      "Epoch 17/100\n",
      "28/28 - 1s - loss: 0.2893 - acc: 0.8626 - val_loss: 0.2980 - val_acc: 0.8631\n",
      "Epoch 18/100\n",
      "28/28 - 1s - loss: 0.2896 - acc: 0.8628 - val_loss: 0.2974 - val_acc: 0.8637\n",
      "Epoch 19/100\n",
      "28/28 - 1s - loss: 0.2895 - acc: 0.8625 - val_loss: 0.2983 - val_acc: 0.8637\n",
      "Epoch 20/100\n",
      "28/28 - 1s - loss: 0.2891 - acc: 0.8624 - val_loss: 0.2983 - val_acc: 0.8629\n",
      "Epoch 21/100\n",
      "28/28 - 1s - loss: 0.2901 - acc: 0.8628 - val_loss: 0.2983 - val_acc: 0.8632\n",
      "Epoch 22/100\n",
      "28/28 - 1s - loss: 0.2888 - acc: 0.8633 - val_loss: 0.2981 - val_acc: 0.8636\n",
      "Epoch 23/100\n",
      "28/28 - 1s - loss: 0.2892 - acc: 0.8622 - val_loss: 0.2984 - val_acc: 0.8634\n",
      "Epoch 24/100\n",
      "28/28 - 1s - loss: 0.2893 - acc: 0.8625 - val_loss: 0.2977 - val_acc: 0.8633\n",
      "Epoch 25/100\n",
      "28/28 - 2s - loss: 0.2883 - acc: 0.8631 - val_loss: 0.2980 - val_acc: 0.8631\n",
      "Epoch 26/100\n",
      "28/28 - 2s - loss: 0.2892 - acc: 0.8633 - val_loss: 0.2981 - val_acc: 0.8638\n",
      "Epoch 27/100\n",
      "28/28 - 2s - loss: 0.2893 - acc: 0.8629 - val_loss: 0.2983 - val_acc: 0.8636\n",
      "Epoch 28/100\n",
      "28/28 - 2s - loss: 0.2882 - acc: 0.8630 - val_loss: 0.2985 - val_acc: 0.8638\n",
      "Epoch 29/100\n",
      "28/28 - 1s - loss: 0.2888 - acc: 0.8632 - val_loss: 0.2988 - val_acc: 0.8636\n",
      "Epoch 30/100\n",
      "28/28 - 1s - loss: 0.2887 - acc: 0.8627 - val_loss: 0.2987 - val_acc: 0.8634\n",
      "Epoch 31/100\n",
      "28/28 - 1s - loss: 0.2885 - acc: 0.8630 - val_loss: 0.2985 - val_acc: 0.8632\n",
      "Epoch 32/100\n",
      "28/28 - 1s - loss: 0.2878 - acc: 0.8634 - val_loss: 0.2990 - val_acc: 0.8635\n",
      "Epoch 33/100\n",
      "28/28 - 1s - loss: 0.2877 - acc: 0.8641 - val_loss: 0.2987 - val_acc: 0.8637\n",
      "Epoch 34/100\n",
      "28/28 - 1s - loss: 0.2878 - acc: 0.8631 - val_loss: 0.2986 - val_acc: 0.8636\n",
      "Epoch 35/100\n",
      "28/28 - 1s - loss: 0.2884 - acc: 0.8633 - val_loss: 0.2987 - val_acc: 0.8635\n",
      "Epoch 36/100\n",
      "28/28 - 1s - loss: 0.2879 - acc: 0.8632 - val_loss: 0.2991 - val_acc: 0.8630\n",
      "Epoch 37/100\n",
      "28/28 - 1s - loss: 0.2875 - acc: 0.8635 - val_loss: 0.2989 - val_acc: 0.8639\n",
      "Epoch 38/100\n",
      "28/28 - 1s - loss: 0.2880 - acc: 0.8632 - val_loss: 0.2996 - val_acc: 0.8638\n",
      "Epoch 39/100\n",
      "28/28 - 1s - loss: 0.2871 - acc: 0.8636 - val_loss: 0.2992 - val_acc: 0.8638\n",
      "Epoch 40/100\n",
      "28/28 - 1s - loss: 0.2874 - acc: 0.8634 - val_loss: 0.2994 - val_acc: 0.8637\n",
      "Epoch 41/100\n",
      "28/28 - 1s - loss: 0.2877 - acc: 0.8632 - val_loss: 0.2992 - val_acc: 0.8631\n",
      "Epoch 42/100\n",
      "28/28 - 1s - loss: 0.2872 - acc: 0.8637 - val_loss: 0.2994 - val_acc: 0.8638\n",
      "Epoch 43/100\n",
      "28/28 - 1s - loss: 0.2874 - acc: 0.8635 - val_loss: 0.2998 - val_acc: 0.8645\n",
      "Epoch 44/100\n",
      "28/28 - 1s - loss: 0.2875 - acc: 0.8634 - val_loss: 0.2996 - val_acc: 0.8637\n",
      "Epoch 45/100\n",
      "28/28 - 1s - loss: 0.2868 - acc: 0.8635 - val_loss: 0.2993 - val_acc: 0.8642\n",
      "Epoch 46/100\n",
      "28/28 - 1s - loss: 0.2874 - acc: 0.8631 - val_loss: 0.3001 - val_acc: 0.8637\n",
      "Epoch 47/100\n",
      "28/28 - 1s - loss: 0.2866 - acc: 0.8642 - val_loss: 0.3000 - val_acc: 0.8644\n",
      "Epoch 48/100\n",
      "28/28 - 1s - loss: 0.2869 - acc: 0.8637 - val_loss: 0.3006 - val_acc: 0.8638\n",
      "Epoch 49/100\n",
      "28/28 - 1s - loss: 0.2859 - acc: 0.8643 - val_loss: 0.3000 - val_acc: 0.8636\n",
      "Epoch 50/100\n",
      "28/28 - 1s - loss: 0.2868 - acc: 0.8640 - val_loss: 0.2999 - val_acc: 0.8646\n",
      "Epoch 51/100\n",
      "28/28 - 1s - loss: 0.2868 - acc: 0.8636 - val_loss: 0.2996 - val_acc: 0.8642\n",
      "Epoch 52/100\n",
      "28/28 - 1s - loss: 0.2863 - acc: 0.8642 - val_loss: 0.2997 - val_acc: 0.8642\n",
      "Epoch 53/100\n",
      "28/28 - 1s - loss: 0.2866 - acc: 0.8639 - val_loss: 0.3000 - val_acc: 0.8638\n",
      "Epoch 54/100\n",
      "28/28 - 1s - loss: 0.2864 - acc: 0.8647 - val_loss: 0.3005 - val_acc: 0.8642\n",
      "Epoch 55/100\n",
      "28/28 - 1s - loss: 0.2858 - acc: 0.8638 - val_loss: 0.3004 - val_acc: 0.8644\n",
      "Epoch 56/100\n",
      "28/28 - 1s - loss: 0.2863 - acc: 0.8636 - val_loss: 0.2999 - val_acc: 0.8644\n",
      "Epoch 57/100\n",
      "28/28 - 1s - loss: 0.2864 - acc: 0.8640 - val_loss: 0.3005 - val_acc: 0.8644\n",
      "Epoch 58/100\n",
      "28/28 - 1s - loss: 0.2859 - acc: 0.8637 - val_loss: 0.3000 - val_acc: 0.8647\n",
      "Epoch 59/100\n",
      "28/28 - 1s - loss: 0.2856 - acc: 0.8647 - val_loss: 0.3001 - val_acc: 0.8640\n",
      "Epoch 60/100\n",
      "28/28 - 1s - loss: 0.2861 - acc: 0.8642 - val_loss: 0.3002 - val_acc: 0.8642\n",
      "Epoch 61/100\n",
      "28/28 - 1s - loss: 0.2863 - acc: 0.8643 - val_loss: 0.3005 - val_acc: 0.8641\n",
      "Epoch 62/100\n",
      "28/28 - 1s - loss: 0.2860 - acc: 0.8640 - val_loss: 0.3004 - val_acc: 0.8639\n",
      "Epoch 63/100\n",
      "28/28 - 1s - loss: 0.2864 - acc: 0.8637 - val_loss: 0.3007 - val_acc: 0.8639\n",
      "Epoch 64/100\n",
      "28/28 - 1s - loss: 0.2854 - acc: 0.8640 - val_loss: 0.3011 - val_acc: 0.8637\n",
      "Epoch 65/100\n",
      "28/28 - 1s - loss: 0.2853 - acc: 0.8641 - val_loss: 0.3012 - val_acc: 0.8639\n",
      "Epoch 66/100\n",
      "28/28 - 1s - loss: 0.2852 - acc: 0.8644 - val_loss: 0.3008 - val_acc: 0.8646\n",
      "Epoch 67/100\n",
      "28/28 - 1s - loss: 0.2855 - acc: 0.8644 - val_loss: 0.3007 - val_acc: 0.8648\n",
      "Epoch 68/100\n",
      "28/28 - 1s - loss: 0.2858 - acc: 0.8641 - val_loss: 0.3012 - val_acc: 0.8641\n",
      "Epoch 69/100\n",
      "28/28 - 1s - loss: 0.2854 - acc: 0.8644 - val_loss: 0.3018 - val_acc: 0.8641\n",
      "Epoch 70/100\n",
      "28/28 - 1s - loss: 0.2851 - acc: 0.8653 - val_loss: 0.3015 - val_acc: 0.8643\n",
      "Epoch 71/100\n",
      "28/28 - 1s - loss: 0.2857 - acc: 0.8642 - val_loss: 0.3023 - val_acc: 0.8635\n",
      "Epoch 72/100\n",
      "28/28 - 1s - loss: 0.2856 - acc: 0.8643 - val_loss: 0.3021 - val_acc: 0.8637\n",
      "Epoch 73/100\n",
      "28/28 - 1s - loss: 0.2849 - acc: 0.8648 - val_loss: 0.3017 - val_acc: 0.8642\n",
      "Epoch 74/100\n",
      "28/28 - 1s - loss: 0.2853 - acc: 0.8642 - val_loss: 0.3018 - val_acc: 0.8639\n",
      "Epoch 75/100\n",
      "28/28 - 2s - loss: 0.2850 - acc: 0.8648 - val_loss: 0.3018 - val_acc: 0.8635\n",
      "Epoch 76/100\n",
      "28/28 - 2s - loss: 0.2848 - acc: 0.8649 - val_loss: 0.3014 - val_acc: 0.8637\n",
      "Epoch 77/100\n",
      "28/28 - 1s - loss: 0.2850 - acc: 0.8646 - val_loss: 0.3020 - val_acc: 0.8640\n",
      "Epoch 78/100\n",
      "28/28 - 1s - loss: 0.2852 - acc: 0.8638 - val_loss: 0.3020 - val_acc: 0.8642\n",
      "Epoch 79/100\n",
      "28/28 - 1s - loss: 0.2849 - acc: 0.8648 - val_loss: 0.3025 - val_acc: 0.8638\n",
      "Epoch 80/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8649 - val_loss: 0.3023 - val_acc: 0.8637\n",
      "Epoch 81/100\n",
      "28/28 - 2s - loss: 0.2848 - acc: 0.8648 - val_loss: 0.3021 - val_acc: 0.8640\n",
      "Epoch 82/100\n",
      "28/28 - 2s - loss: 0.2845 - acc: 0.8640 - val_loss: 0.3024 - val_acc: 0.8637\n",
      "Epoch 83/100\n",
      "28/28 - 1s - loss: 0.2845 - acc: 0.8647 - val_loss: 0.3026 - val_acc: 0.8638\n",
      "Epoch 84/100\n",
      "28/28 - 1s - loss: 0.2846 - acc: 0.8648 - val_loss: 0.3025 - val_acc: 0.8643\n",
      "Epoch 85/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8648 - val_loss: 0.3031 - val_acc: 0.8641\n",
      "Epoch 86/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8649 - val_loss: 0.3030 - val_acc: 0.8644\n",
      "Epoch 87/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8646 - val_loss: 0.3032 - val_acc: 0.8642\n",
      "Epoch 88/100\n",
      "28/28 - 1s - loss: 0.2842 - acc: 0.8646 - val_loss: 0.3031 - val_acc: 0.8646\n",
      "Epoch 89/100\n",
      "28/28 - 1s - loss: 0.2842 - acc: 0.8656 - val_loss: 0.3032 - val_acc: 0.8640\n",
      "Epoch 90/100\n",
      "28/28 - 1s - loss: 0.2851 - acc: 0.8648 - val_loss: 0.3032 - val_acc: 0.8638\n",
      "Epoch 91/100\n",
      "28/28 - 1s - loss: 0.2845 - acc: 0.8650 - val_loss: 0.3034 - val_acc: 0.8632\n",
      "Epoch 92/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8655 - val_loss: 0.3035 - val_acc: 0.8638\n",
      "Epoch 93/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8647 - val_loss: 0.3034 - val_acc: 0.8636\n",
      "Epoch 94/100\n",
      "28/28 - 1s - loss: 0.2843 - acc: 0.8646 - val_loss: 0.3034 - val_acc: 0.8633\n",
      "Epoch 95/100\n",
      "28/28 - 1s - loss: 0.2834 - acc: 0.8655 - val_loss: 0.3035 - val_acc: 0.8640\n",
      "Epoch 96/100\n",
      "28/28 - 1s - loss: 0.2836 - acc: 0.8654 - val_loss: 0.3038 - val_acc: 0.8637\n",
      "Epoch 97/100\n",
      "28/28 - 1s - loss: 0.2839 - acc: 0.8649 - val_loss: 0.3034 - val_acc: 0.8640\n",
      "Epoch 98/100\n",
      "28/28 - 1s - loss: 0.2840 - acc: 0.8647 - val_loss: 0.3031 - val_acc: 0.8643\n",
      "Epoch 99/100\n",
      "28/28 - 1s - loss: 0.2844 - acc: 0.8644 - val_loss: 0.3036 - val_acc: 0.8640\n",
      "Epoch 100/100\n",
      "28/28 - 1s - loss: 0.2837 - acc: 0.8653 - val_loss: 0.3034 - val_acc: 0.8640\n"
     ]
    }
   ],
   "source": [
    "results_dropout = model_dropout.fit(X_train_sc, y_train,\n",
    "                                   validation_data=(X_test_sc, y_test),\n",
    "                                   batch_size=9192,\n",
    "                                   epochs=100,\n",
    "                                   verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_features=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=2)\n",
    "rf.fit(X_train,y_train)\n",
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8462196078431372 0.8387764705882353\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 400, max_depth=20, min_samples_leaf=3, bootstrap=True)\n",
    "rf.fit(X_train_sc,y_train)\n",
    "print(rf.score(X_train_sc, y_train), rf.score(X_test_sc, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=3, bootstrap=False)\n",
    "rf.fit(X_train,y_train)\n",
    "print(rf.score(X_train, y_train), rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=2, bootstrap = True)\n",
    "et.fit(X_train,y_train)\n",
    "print(et.score(X_train, y_train), et.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators = 300, max_depth=10, min_samples_leaf=2, bootstrap = False)\n",
    "et.fit(X_train,y_train)\n",
    "print(et.score(X_train, y_train), et.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=300)\n",
    "gb.fit(X_train, y_train)\n",
    "print(gb.score(X_train, y_train), gb.score(X_test, y_test),  \n",
    "      cross_val_score(gb, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions \n",
    "preds_gb = gb.predict(X_test)\n",
    "\n",
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test, preds_gb)\n",
    "ConfusionMatrixDisplay(cm, display_labels=['0','1','2','3']).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'importance' : gb.feature_importances_, 'feature_names' : X_train.columns}).sort_values(by='importance', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb2 = GradientBoostingClassifier(n_estimators=500)\n",
    "gb2.fit(X_train, y_train)\n",
    "print(gb2.score(X_train, y_train), gb2.score(X_test, y_test),  \n",
    "      cross_val_score(gb2, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb3 = GradientBoostingClassifier(n_estimators=500, \n",
    "                        min_samples_split = 100, \n",
    "                        min_samples_leaf = 50, \n",
    "                        max_depth=8,\n",
    "                        max_features='sqrt',\n",
    "                        subsample=0.8)\n",
    "gb3.fit(X_train, y_train)\n",
    "print(gb3.score(X_train, y_train), gb3.score(X_test, y_test),  \n",
    "      cross_val_score(gb3, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
